{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Deep Q Learning\n",
    "> by Khizr Ali Pardhan | Alik604\n",
    "\n",
    "[best video](https://www.youtube.com/watch?v=H9uCYnG3LlE) | [code](https://raw.githubusercontent.com/philtabor/Youtube-Code-Repository/master/ReinforcementLearning/DeepQLearning/simple_dqn_torch_2020.py)- most of my code if from here\n",
    "\n",
    "### done\n",
    "* Steal some samplecode\n",
    "    - why reimplement the wheel? \n",
    "* [skim the paper](https://arxiv.org/pdf/1509.06461.pdf) to feel smart | Deep Reinforcement Learning with Double Q-learning\n",
    " \n",
    "    \n",
    "### todo \n",
    "\n",
    "* gym addon -> robot\n",
    "    - https://github.com/nplan/gym-line-follower \n",
    "    - https://github.com/jr-robotics/robo-gym \n",
    "\n",
    "more todo\n",
    "```\n",
    "https://www.youtube.com/watch?v=H9uCYnG3LlE\n",
    "https://www.youtube.com/watch?v=2vJtbAha3To\n",
    "https://www.youtube.com/watch?v=hlv79rcHws0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Deep Q Learning\n",
    "[source](https://medium.com/analytics-vidhya/introduction-to-double-deep-q-learning-ddqn-473833cf1a70) \n",
    "\n",
    "In Double Deep Q Learning, the agent uses two neural networks to learn and predict what action to take at every step. \n",
    "\n",
    "One network, referred to as the Q network or the online network, is used to predict what to do when the agent encounters a new state. \n",
    "\n",
    "It takes in the state as input and outputs Q values for the possible actions that could be taken. \n",
    "\n",
    "the online network takes **in a vector of four values** (observation) and **outputs a vector of two Q values**, one for the value of moving left in the current state, and one for the value of moving right in the current state.\n",
    "\n",
    "The agent will choose the action that has the higher corresponding Q value output by the online network. **like a argmax** \n",
    "\n",
    "Double DQNs handles the problem of the overestimation of Q-values.\n",
    "\n",
    "The solution is: when we compute the Q target, we tend to use 2 networks to decouple the action selected from the target Q value generation. \n",
    "\n",
    "We:\n",
    "* use our DQN network to select what is the best action required for the succeeding state (the action with the very best Q value).\n",
    "* use our target network to calculate the target Q value of taking that action at the next state.\n",
    "* Deep Q Network — selecting the best action a with maximum Q-value of next state.\n",
    "* Target Network — calculating the estimated Q-value with action a selected above.\n",
    "\n",
    "Therefore, Double Deep Q Network helps us reduce the overestimation of Q values and helps us train quicker and have more steady learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "import time \n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://raw.githubusercontent.com/philtabor/Youtube-Code-Repository/master/ReinforcementLearning/DeepQLearning/simple_dqn_torch_2020.py\n",
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, lr, input_dims, fc1_dims, fc2_dims, \n",
    "            n_actions):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
    "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        self.fc2_5 = nn.Linear(self.fc2_dims, int(self.fc2_dims/2))\n",
    "        self.fc3 = nn.Linear(int(self.fc2_dims/2), self.n_actions)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        print(self.device)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = state.float()\n",
    "#         print(state.dtype)\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc2_5(x))\n",
    "        actions = self.fc3(x)\n",
    "\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, gamma, epsilon, lr, input_dims, batch_size, n_actions,\n",
    "            max_mem_size=100000, eps_end=0.05, eps_dec=5e-4, ALIs_over_training=2):\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.eps_min = eps_end\n",
    "        self.eps_dec = eps_dec\n",
    "        self.lr = lr\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.mem_size = max_mem_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mem_cntr = 0\n",
    "        self.iter_cntr = 0\n",
    "        self.replace_target = 30\n",
    "        self.ALIs_over_training = ALIs_over_training\n",
    "\n",
    "        self.Q_eval = DeepQNetwork(lr, n_actions=n_actions, input_dims=input_dims,\n",
    "                                    fc1_dims=512, fc2_dims=256)\n",
    "        self.Q_next = DeepQNetwork(lr, n_actions=n_actions, input_dims=input_dims,\n",
    "                                    fc1_dims=512, fc2_dims=256) # 64 ,64, if not updating pramas\n",
    "\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_dims), dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_dims), dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
    "\n",
    "    def store_transition(self, state, action, reward, state_, terminal):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.reward_memory[index] = reward\n",
    "        self.action_memory[index] = action\n",
    "        self.terminal_memory[index] = terminal\n",
    "\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        if np.random.random() > self.epsilon:\n",
    "            state = T.tensor([observation]).to(self.Q_eval.device)\n",
    "            actions = self.Q_eval.forward(state)\n",
    "            action = T.argmax(actions).item()\n",
    "        else:\n",
    "            action = np.random.choice(self.action_space)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "        if self.mem_cntr < self.batch_size: #maybe self.batch_size*2... IDK about this \n",
    "            return\n",
    "\n",
    "        \n",
    "        \n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "\n",
    "        # replace=False means dont given duplicates. max_mem isnt mutated\n",
    "        batch = np.random.choice(max_mem, self.batch_size, replace=False) # todo decrease and force train on last 3 \n",
    "        \n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "\n",
    "        state_batch = T.tensor(self.state_memory[batch]).to(self.Q_eval.device)\n",
    "        new_state_batch = T.tensor(self.new_state_memory[batch]).to(self.Q_eval.device)\n",
    "        action_batch = self.action_memory[batch]\n",
    "        reward_batch = T.tensor(self.reward_memory[batch]).to(self.Q_eval.device)\n",
    "        terminal_batch = T.tensor(self.terminal_memory[batch]).to(self.Q_eval.device)\n",
    "        \n",
    "#         N = 2 if self.iter_cntr > self.batch_size else 1 # maybe use self.mem_cntr\n",
    "        for i in range(self.ALIs_over_training): # Ali over training \n",
    "            self.Q_eval.optimizer.zero_grad()\n",
    "            q_eval = self.Q_eval.forward(state_batch)[batch_index, action_batch]\n",
    "            q_next = self.Q_eval.forward(new_state_batch)\n",
    "            q_next[terminal_batch] = 0.0\n",
    "\n",
    "            q_target = reward_batch + self.gamma*T.max(q_next, dim=1)[0]\n",
    "\n",
    "            loss = self.Q_eval.loss(q_target, q_eval).to(self.Q_eval.device)\n",
    "            loss.backward()\n",
    "            self.Q_eval.optimizer.step()\n",
    "\n",
    "            self.iter_cntr += 1\n",
    "            \n",
    "            if self.iter_cntr % self.replace_target == 0:\n",
    "                self.Q_next.load_state_dict(self.Q_eval.state_dict())\n",
    "                \n",
    "        self.epsilon = self.epsilon - self.eps_dec if self.epsilon > self.eps_min else self.eps_min\n",
    "        \n",
    "        # This isn't my code. IDK why we dont optimize Q_next, however, I trust the author (youtube: machine learning with Phil). \n",
    "        # This was because the two networks are different... IDK how to update the Q_next network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1') # have batch size 32, and make the loop labled \"Ali over training\" run maybe 2 times \n",
    "# env = gym.make('LunarLander-v2') # score > 200 # have batch size 64, and make the loop labled \"Ali over training\" run maybe 2 to 5 times \n",
    "\n",
    "## these dont work this my code\n",
    "# env = gym.make(\"BipedalWalker-v3\")\n",
    "# env = gym.make('BipedalWalkerHardcore-v3')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env= gym.make('Pong-v0')\n",
    "\n",
    "print(env.action_space.n)\n",
    "print(env.observation_space)\n",
    "# print(env.unwrapped.get_action_meanings())\n",
    "# help(env.unwrapped)\n",
    "\n",
    "env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "episode  0 score 48.00 average score 48.00 epsilon 1.00\n",
      "episode  1 score 14.00 average score 31.00 epsilon 1.00\n",
      "episode  2 score 24.00 average score 28.67 epsilon 0.99\n",
      "episode  3 score 26.00 average score 28.00 epsilon 0.97\n",
      "episode  4 score 18.00 average score 26.00 epsilon 0.96\n",
      "episode  5 score 22.00 average score 25.33 epsilon 0.95\n",
      "episode  6 score 25.00 average score 25.29 epsilon 0.94\n",
      "episode  7 score 16.00 average score 24.12 epsilon 0.93\n",
      "episode  8 score 17.00 average score 23.33 epsilon 0.92\n",
      "episode  9 score 27.00 average score 23.70 epsilon 0.90\n",
      "episode  10 score 49.00 average score 23.80 epsilon 0.88\n",
      "episode  11 score 19.00 average score 24.30 epsilon 0.87\n",
      "episode  12 score 17.00 average score 23.60 epsilon 0.86\n",
      "episode  13 score 10.00 average score 22.00 epsilon 0.85\n",
      "episode  14 score 22.00 average score 22.40 epsilon 0.84\n",
      "Time taken: 6.0605\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "agent = Agent(gamma=0.99, epsilon=1.0, batch_size=64, n_actions=env.action_space.n, eps_end=0.01,\n",
    "              input_dims=[observation.shape[0]], lr=0.001, eps_dec=5e-4*1.1, ALIs_over_training=2) # changed from eps_dec=5e-4\n",
    "\n",
    "scores, eps_history = [], []\n",
    "n_games = 150\n",
    "\n",
    "start = time.time()\n",
    "time.sleep(3)\n",
    "for i in range(n_games):\n",
    "    score = 0\n",
    "    done = False\n",
    "    observation = env.reset()\n",
    "    while not done:\n",
    "\n",
    "        action = agent.choose_action(observation)\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        agent.store_transition(observation, action, reward, observation_, done)\n",
    "        agent.learn()\n",
    "        observation = observation_\n",
    "    scores.append(score)\n",
    "    eps_history.append(agent.epsilon)\n",
    "\n",
    "    \n",
    "\n",
    "    if i % 1 == 0:\n",
    "        avg_score = np.mean(scores[-10:])\n",
    "        print('episode ', i, 'score %.2f' % score, 'average score %.2f' % avg_score, 'epsilon %.2f' % agent.epsilon)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time taken: {(end - start):.4f}')\n",
    "\n",
    "x = [i+1 for i in range(n_games)]\n",
    "filename = 'lunar_lander.png'\n",
    "\n",
    "## Batch since 32. cart pole. eps_dec=5e-4*1.5\n",
    "# 31, 35 sec for CUDA, 80 steps.                             max 10-moving-average, 204\n",
    "# 28, 30 sec for CPU, 80 steps.                              max 10-moving-average, 170\n",
    "# 16 sec for CPU reduced params, 80 steps.                   max 10-moving-average, 163\n",
    "# 44 sec for CUDA extra params, 80 steps.                    max 10-moving-average, 307 (or 197)\n",
    "# 55, 58 sec for CUDA extra params, bridge layer, 80 steps.  max 10-moving-average, 246, 261\n",
    "# 135 sec for CUDA extra params, bridge layer, DOUBLE TRAINING. 80 steps.  max 10-moving-average, 354 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is:24.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEKCAYAAABDkxEYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd4FNX6wPHvphFall4DDCggAQJIpEhVFMGhiyiKgg0b2PDqWH4yl6vXUVEEwYKogHpVLqICowIiHUQCCEiROkJAmsBKkRLI74+ZXNcQkgCZzO7m/TxPnuzMnNl9kyfZd8+Zd87xZWRkIIQQQoSqKK8DEEIIIXIiiUoIIURIk0QlhBAipEmiEkIIEdIkUQkhhAhpkqiEEEKENElUQgghQpokKiGEECFNEpUQQoiQFuN1APmlXLlyGYqieB2GEEKEleXLl+/PyMgo73UcOYmYRKUoCqmpqV6HIYQQYcXn8/3qdQy5kaE/IYQQIU0SlRBCiJAmiUoIIURIk0QlhBAipEmiEkIIEdJcq/pTNPN9oAuw1zLUBtkc9wEjgeuBY8AAy1BXOMf6A886TZ+3DHWCW3GyehLMHgaBNPAnQofnILmPay8nhBDi/LjZoxoPdMrheGegtvM1EHgLQNHMMsBQoDnQDBiqaGZpVyJcPQmmPQSBHUCG/X3aQ/Z+IYQQIcG1HpVlqPMVzVRyaNIdmGgZagbwg6KZpRTNrAy0B2ZZhnoAQNHMWdgJ75N8D3L2MDj159/3nfqTP8z/Y9zuRhf99CXjY7mleXWKF4mY29WEEKLAefkOWhXYEbSd5uw71/6zKJo5ELs3RtTRk+cfQSAt290lju/hjTmbz//5ssjIgP/8uJ2RNzcmObHURT+fEEIURl4mKl82+zJy2H8Wy1DHAmMBUr4bmm2bHPkTnWG/v4sqlci2R9Xzfrqsftj6O49+9hO93lzM49fVZWCbWkRFZffjCSGEOBcvq/7SgGpB24nArhz2578Oz0Fs0b/viy1q788HLWqV5ZuH29CxfkWMbzbQ772l7A4cz5fnFkKIwsLLRDUVuF3RTJ+imS2AgGWovwEzgI6KZpZ2iig6OvvyX3If6DoK/NUAn/2966h8rforVSyOMbdczks3NGTl9kN0HjmfmWt359vzCyFEpPNlZJz/iFleKJr5CXZhRDlgD3YlXyyAZahvO+Xpo7ELJY4Bd1iGmuqceyfwtPNUL1iG+kFur5eSkpIR6pPSbtl3hIc+WcnaXX/Qr0V1nrk+iaJx0V6HJYQoxHw+3/KMjIwUr+PIiWuJqqCFQ6ICOJF+mldnbmTs/K3UrlCCUX2bUK9ygtdhCSEKqXBIVDIzRQErEhPN09fX48O7mnHoz1N0H72I9xduI1I+MAghRH6TROWRNrXL8+3DbWhTuxzDpq/jjvHL2H/khNdhCSFEyJFE5aGyJYowrn8Kw7rXZ/GW3+n0+gLm/rLX67CEECKkSKLymM/n4/aWClMHtaJM8VgGfLCMf01fx4n0016HJoQQIUESVYi4rFICUwe15vaWNXhv4TZ6jFnM5r2HvQ5LCCE8J4kqhMTHRjOsewPG3Z7Cnj+O0+WNhXy89FcptBBCFGqSqELQNUkV+fbhNlyhlOGZL37mvo+Wc/BC5jIUQogIIIkqRFVIiGfCHc145vp6fL9hL51HLmDxlv1ehyWEEAVOElUIi4rycU/bWnzxQCuKxUVz67ilvPztBk6dPuN1aEIIUWAkUYWBBlX9TBvcmj5Nq/Hm3C3c+PYSmdxWCFFoSKIKE8WLxPBS72RG39KEjXsO03X0Qpb/etDrsIQQwnWSqMJMl+QqTHngSuJjo+g79gcmpZ69npYQQkQSSVRh6LJKCUx9sDVX1CzNE5NXo09dK9ethBARSxJVmCpdPI4JdzTjzlY1Gb/Yov/7P0oJuxAiIkmiCmMx0VE81zWJV3onk2odpNuYhWzY/YfXYQkhRL6KcfPJFc3sBIwEooFxlqEaWY7XAN4HygMHgH6WoaY5x14GVOxkOgt42DJUmaIhGzemVOPSCiW498Pl9HpzMa/e2IjODSt7HZYQIpLo/mggFdiJHuiC7h8PtAMCTosB6IGf3Hhp13pUimZGA2OAzkAS0FfRzKQszYYDEy1DTQaGAS86514JtAKSgQbAFdi/EHEOTaqXZtrg1tSpWJL7P17Ba7M2cuaM5HUhRL55GFifZd8/0AONnS9XkhS4O/TXDNhsGepWy1BPAp8C3bO0SQJmO4/nBB3PAOKBOKAI9hL2e1yMNSJUTIjn04Et6N00kVGzN3HvR8s5ciLd67CEEOFO9ydij3CN8+Ll3UxUVYHg2uk0Z1+wVcANzuOeQElFM8tahroEO3H95nzNsAw1ayYX2YiPjeaV3skM7ZrE9xv20uvNRfz6+1GvwxJChKghLePKoftTg74GZtPsdeAJIGt58Qvo/tXo/hHo/iJuxejmNSpfNvuyjkU9DoxWNHMAMB/YCaQrmnkpUA9IdNrNUjSzrWWo84NPVjRzIDAQIEoq3v7H5/NxR6ua1KlYkgf/s4Juoxcx+pYmtKld3uvQhBAh5tUlJ/cPX3wi5ZwNdH8XYC96YDm6v33QkaeA3dgjX2OBJ7Ev4eQ7N3tUaUC1oO1EYFdwA8tQd1mG2ssy1CbAM86+AHbv6gfLUI9YhnoE+AZokfUFLEMdaxlqimWoKWWKx7n1c4StVpeWY+qDramUEE//939k3IKtsmSIEOJ8tQK6ofst7Es4V6P7P0IP/IYeyEAPnAA+wL7c4wo3E9UyoLaimTUVzYwDbgamBjdQNLOcopmZMTyFXQEIsB1op2hmjKKZsdiFFDL0dwGqly3GlAeupGNSJZ431zPkv6s4fkpWDxZC5JEeeAo9kIgeULDfx79HD/RD99ulxbrfB/QAfnYrBNcSlWWo6cAgYAZ2kplkGepaRTOHKZrZzWnWHvhF0cyNQEXgBWf/ZGALsAb7OtYqy1CnuRVrpCteJIY3b72cx66tw5QVO7npHZnUVghx0T5G96/Bfp8uBzzv1gv5ImUoKCUlJSM1NdXrMELejLW7eeyznyhWJIa3+zWlaY3SXockhPCQz+dbnpGRce5rVCFAZqYoZK6rX4kpD7SiaGy0TGorhAgLkqgKobqVSjJ1UCua1yojk9oKIUKeJKpCqlSxOD4YcAV3t/5rUtsDUuIvhAhBkqgKsZjoKJ7tksSrNzYi9deDXP3qXMYv2ia9KyFESJFEJbihaSJTB7UiqXIC+rR1XDdiPrPW7ZF7roQQIUESlQDsxRg/vrs57/VPAR/cMzGVW95dytpdgdxPFkIIF0miEv/j8/noUK8iMx5pyz+71Wf97j/o8sZCnpi8ij1/yH1XQghvSKISZ4mNjqL/lQrzHr+Ku1vX5IuVO7lq+FxGzd7EnydlVgshRMGSRCXOyV8slmfUJL57rB3t6pTntVkbuWr4XKasSJO1roQQBUYSlchVjbLFeatfUybd25IKCUV4bNIquo9ZxNKtv3sdmhCiEJBEJfKsWc0yfPlAK0bc1Ij9R05w09gfuPfDVKz9st6VEMI9kqjEeYmK8tGzSSLfD2nPkGvrsGDTfq4dMY9/TV9H4Ngpr8MTQkQgSVTighSNi2Zwh9rMfbw9vZok8v6ibbQbPocP5IZhIUQ+k0QlLkqFhHhe6p2MObgN9ask8E+5YVgIkc8kUYl8kVQlgY/uas77A+SGYSFE/pJEJfKNz+fj6sv+umF4g3PD8LBp62RVYSHEBYtx88kVzewEjASigXGWoRpZjtfAXn6+PHAA6GcZappzrDowDqgGZADXW4ZquRmvyB+ZNwz3aFKVV2Zs4P1F25i3cS8jbmpMcmIpr8MTQoQZ13pUimZGA2OAzkAS0FfRzKQszYYDEy1DTQaGAS8GHZsIvGIZaj2gGbDXrViFO/xFY3m+R0Mm3tmMoydO0/PNxbz+3UYpthBCnBc3h/6aAZstQ91qGepJ4FOge5Y2ScBs5/GczONOQouxDHUWgGWoRyxDPeZirMJFbeuUZ8YjbemaXJnXv9vEDW8tZvPeI16HJYQIE24mqqpA8Drnac6+YKuAG5zHPYGSimaWBeoAhxTNnKJo5kpFM19xemgiTPmLxfL6zU0Yc8vl7DhwDHXUAt5fuE2mYhJC5MrNa1S+bPZlfVd6HBitaOYAYD6wE0h34moDNAG2A58BA4D3gk9WNHMgMBAgSlanDQtqcmWuUEqjTVnDsOnrmLVuD8P7NKJqqaJehyaECFFu9qjSsAshMiUCu4IbWIa6yzLUXpahNgGecfYFnHNXOsOG6cCXwOVZX8Ay1LGWoaZYhppSpnicWz+HyGcVEuJ5r38KRq+GrE47RKcR85m8PE3uuxJCZMvNRLUMqK1oZk1FM+OAm4GpwQ0UzSynaGZmDE9hVwBmnlta0czyzvbVwDoXYxUFzOfzcXOz6nzzcFvqVU7g8f+u4t4Pl7P/yAmvQxNChBjXEpXTExoEzADWA5MsQ12raOYwRTO7Oc3aA78omrkRqAi84Jx7GntYcLaimWuwhxHfdStW4Z3qZYvxycAWPH39Zcz9ZR/XjZjPzLW7vQ5LCBFCfJEy3JKSkpKRmprqdRjiIvyy+zCPfvYT6377g95NE3muaxIJ8bFehyVERPP5fMszMjJSvI4jJzIzhQgZdSuV5MsHWzH46kuZsiKNzq8vYPGW/V6HJYTwmCQqEVLiYqIY0rEuk++/kriYKG55d6lMwSREISeJSoSky6uXxnyoNf1b1uD9RdtQRy1gddohr8MSQnhAEpUIWcXiYvhn9wZ8eJdMwSREYSaJSoS8NrXtKZi6NaoSNAXTYa/DEkIUEElUIiz4i8Uy4qbGvHlr5hRMC5m8PM3rsIQQBcDVZT6EyG/XN6xMilKahz/5icf/u4qfdhzk/7okUSRGpoIUwlW6PxpIBXaiB7qg+2tiTzZeBlgB3IYecGUuO+lRibBToWQ8H97VjHvb1eKjH7bT550f2HXoT6/DEiLSPYw9eUOml4AR6IHawEHgLrdeWBKVCEsx0VE81bkeb916OVv2HqHLGwtZvFnuuRLCFbo/EVCxF7MF3e/DntpustNiAtDDrZeXoT8R1jo3rEydSiW578Pl9HtvKU90uox729bC58tu8n4hRFZDWsaVQ/cHT+szFj0wNkuz14EngJLOdlngEHog3dnObhmnfCOJSoS9S8qX4MsHW/HE56sxvtnAyu0HGX5jI0rK9EtC5OrVJSf3D1984txTKOn+LsBe9MBydH97Z29elnHKNzL0JyJC8SIxjO7bhGfVeny3fi/dRy9i4x4pYRciH7QCuqH7Leziiauxe1il0P2ZnZ2zlnHKT5KoRMTw+Xzc3aYW/7m7OX8cT6fHmEVMW+Xa/44QhYMeeAo9kIgeULCXa/oePXArMAfo7bTqD3zlVgiSqETEaV6rLOZDrUmqnMDgT1YybNo6mc1CiPz3JPAYun8z9jWr93Jpf8FkmQ8RsU6mn+HfX69n/GKLZkoZRt/ahAol470OS4iQIst8COGhuJgo9G71GXlzY9bsDNBl1EKWWQe8DksIcZ5crfpTNLMTMBKIBsZZhmpkOV4De/n58sABoJ9lqGlBxxOwbzD7wjLUQW7GKiJX98ZVuaxSAvd9tJy+Y3/g6evrcUcrRUrYhQgTrvWoFM2MBsYAnYEkoK+imUlZmg0HJlqGmgwMA17McvxfwDy3YhSFR91KJflqUCuuuqwCw6av4+FPf+LYyfTcTxRCeM7Nob9mwGbLULdahnoSu6yxe5Y2ScBs5/Gc4OOKZjYFKgIzXYxRFCIJ8bG8068p/7iuLtNX76LnmMVs3XfE67CEELlwc+ivKrAjaDsNaJ6lzSrgBuzhwZ5ASUUzy2LPG/UqcBvQ4VwvoGjmQGAgQNRRV+ZCFBEmKsrHg1ddSqPEUjz06Uq6j17E8D6NuK5+Ja9DE0Kcg5s9qrzcufw40E7RzJVAO2AnkA48AHxtGeoOcmAZ6ljLUFMsQ00pUzwuP2IWhUTr2uWYNrg1tcoX594Pl/PStxs4fSYyKmCFiDRuJqo0oFrQ9ll3LluGussy1F6WoTYBnnH2BYCWwCBFMy3s61i3K5r5t0IMIS5W1VJF+ezelvRtVp235m6h//s/8vuRE16HJYTIws2hv2VAbUUza2L3lG4GbgluoGhmOeCAZahngKewKwCxDPXWoDYDgBTLUDUXYxWFVHxsNC/2akiT6qV49sufuXbEfAa2rcVtLWpQvIhMhSlEKHCtR2UZajowCJiBXWI+yTLUtYpmDlM0s5vTrD3wi6KZG7ELJ15wKx4hctInpRpfPdiKhlX9GN9soM3Lc3h73haOnpDKQCG8JjNTCJHFiu0HGfndJuZt3EeZ4nHSwxIRLRxmppBEJcQ5SMIShYEkqgIkiUq4RRKWiGSSqAqQJCrhNklYIhJJoipAkqhEQZGEJSJJxCQqRTN7AS8BFbBv5PUBGZahJrgbXt5JohIFLWvCuqdNLW5vKQlLhJdISlSbga6Woa53P6QLI4lKeCU4YZUuFsvAtpdIwhJhIxwSVV7vo9oTyklKCC9dXr00E+5sxpQHriQ5sRQvfbuB1i99z1tz5T4sIfJDXntUI4FKwJfA/+aYsQx1inuhnR/pUYlQIT0sEU4KtEel+1sDtdEDH6D7ywMl0APbcjstr/85CcAxoGPQvgwgZBKVEKEis4eVmbBe+nYD7y3cyqCrLqVv8+oUiYn2OkQhCp7uHwqkAHWBD4BY4COgVW6nStWfEC5b/utBXv52A0u3HSCxdFEeu7YO3RtXJTpKVhgW3iuwHpXu/wloAqxADzRx9q1GDyTndmqeelSKZiYCb2BnvgxgIfBw8LLxQojsNa1Rmk8HtmD+pv28/O0GHpu0infmbeUf19WlQ70K+HySsEShcBI9kIHut3tHur94Xk/MazHFB8BUoAr2gojTnH1CiDzw+Xy0q1OeaYNa80bfJpxIP83dE1O58e0l/LjtgNfhCVEQJqH73wFKofvvAb4D3s3LiXktpvjJMtTGue3zkgz9iXBy6vQZJqXuYOR3m9h7+ARX1S3PP667jKQqIXNroigkCriY4lrsWgcfMAM9MCsvp+W1mGK/opn9gE+c7b7A7+cdpBACgNjoKG5tXoNeTRKZsMTizTmbUd9YQLdGVXjs2jrUKJvnUREhQp/uj8ZOTNcAeUpOwfI69Hcn0AfYDfwG9Hb2CSEuQtG4aO5rdwkLnria+9tdwoy1u+nw6jz+78uf2Xv4uNfhCZE/9MBp4Bi6338hp7ta9adoZidgJBANjLMM1chyvAb2qr7lgQNAP8tQ0xTNbAy8hV0Wfxp4wTLUz3J6LRn6E5Fg7x/HGfX9Jj79cQex0VHc2Vrh3naXkBAf63VoIkIVYNXfJKAFdo/q6F/7Aw/ldmqOQ3+KZr6BXeWXLctQz/kCimZGA2OAa4E0YJmimVMtQ10X1Gw4MNEy1AmKZl4NvAjchn3P1u2WoW5SNLMKsFzRzBmWoR7K7QcSIpxVSIjn+R4Nubt1LV6btZExc7bw8dLtPND+Em5vqRAfK/dgibBlOl/nLbdrVBfTRWkGbLYMdSuAopmfAt2B4ESVBDzqPJ6DPfMFlqFuzGxgGeouRTP3Yve6JFGJQkEpV5xRfZswsG0ths/8hX9/vYH3F1o8ck1tejdNJCY6r6P2QoQIPTAB3R8H1HH2/IIeOJWXU3NMVJahTriIsKoCO4K204DmWdqsAm7AHh7sCZRUNLOsZaj/K9RQNLMZEAdsuYhYhAhLDar6GX9HM37Y+jsvf7sBbcoaxs7fyuPX1aVzg0pyD5YIH7q/PTABsLCr/qqh+/ujB+bndmpuQ3+vW4b6iKKZ08hmCNAy1G45nJ7df1DW53gcGK1o5gBgPrAT+N8snopmVgY+BPpbhnomm/gGAgMBoo6ezOlHESKstahVls/vv5Lv1u/llRkbeODjFSQn+nmldyPqVirpdXhC5MWrQEf0wC8A6P462JXkTXM7Mbehvw+d78MvIKg0oFrQdiKwK7iBZai7gF4AimaWAG6wDDXgbCdgj2c+axnqD9m9gGWoY4GxACnfDY2MuaCEOAefz8e1SRW5+rIKfLlyJ8a3G7jhrcW8cUsTrqpbwevwhMhN7P+SFIAe2Ijuz1OVUG5Df8ud7/My9ymaWRqoZhnq6lyeexlQW9HMmtg9pZuBW4IbKJpZDjjg9Jaewq4ARNHMOOAL7EKL/+blBxGisIiO8nFD00SuvLQsd09I5a7xy3iuSxL9r1RkKFDkP90fjz3iVQQ7Z0xGDwxF948H2gEBp+UA9MBPOTxTKrr/Pf7qAN0KLM9LCHmd628u0M1p/xOwT9HMeZahPnaucyxDTVc0cxAwA7s8/X3LUNcqmjkMSLUMdSrQHnhR0cwM7F/Eg87pfYC2QFlnWBBggGWoOf0ShChUKvuLMuneljz62U/o09axZd9RhnZNkkILkd9OAFejB444PaCF6P5vnGP/QA9MzuPz3I/9Hv8Q9qWh+cCbeTkxr1MorbQMtYmimXdj96aGKpq52jLUXGe9LShyH5UorM6cyeClGRt4Z95W2tQux+hbLsdfVO67EnlzXvdR6f5i2JOS3+98Tc9zorInoT3u3PybOVtFEfTAsdxOzetHrxinsKEPMD2P5wghCkBUlI+nOtfj5RuSWbLld254azHbf8/1f18IAIa0jCuH7k8N+hp4ViPdH+0s07EXmIUeWOocecFeqsM/At1fJJeXmg0UDdouij0xba7yOtffMOwhvEWWoS5TNLMWsCmP5wohCkCfK6pRrUwx7v94Od3HLOSd21JoVrOM12GJEPfqkpP7hy8+kXOPyu4FNUb3lwK+QPc3wK4r2I19+9BY4EnsXHEu8eiBI0HPecTpoeVKFk4UIsJs23+Uu8YvY8fBYxi9krmhaaLXIYkQdt5TKNkr9R5FDwwP2tceeBw90CWH8xYBg9EDK5ztFOAN9EDL3F4yr8UUtbBvym2BfS/UEuARy1BzXeteCFGwapYrzhcPtOL+j5cz5L+r2Lr/CEOurUuUrCgsLoTuLw+cQg8cQvcXBa4BXkL3V0YP/Ibu9wE9gJ9zeaZHgP+i+3dh55EqwE15CSGv16j+A0wCKjtP/l/g0zyeK4QoYP5isUy4sxl9m1VnzJwtPPifFfx58rTXYYnwVBmYg+5fjX3b0Sz0wHTgY3T/GmANUA54Ptuzdf8V6P5K6IFlwGXAZ9gTO3wL5Kmzk9drVD7LUD8M2v7IKT0XQoSo2Ogo/t2zAZeUL84LX68n7Z0ljOufQsWEeK9DE+FED6wGmmSz/+o8PsM72L0wgJbA08BgoDH2ta3euT1BXhPVHEUzNexeVAZ2d81UNLMMgGWospa2ECHI5/Nxd5taKGWL8/CnK+k+ehHj+qfQoOoFLQskxIWIRg9k5oibgLHogc+Bz51KwlzldejvJuBe7BnO52LXz9+JfVexVDAIEeKuSarI5PuvJMoHN769hBlrd3sdkig8otH9mZ2iDsD3Qcfy1FnKUyPLUGueZ2BCiBBTr3ICXw5qxT0Tl3PfR8t5stNl3Nu2lky7JNz2CTAP3b8f+BNYAIDuv5S/pl/KUY49KkUznwh6fGOWY/8+z2CFEB6rUDKezwa2QG1YGeObDTwxeTUn089amECI/KMHXgCGAOOB1uiBzHuiorCvVeUqtx7VzcDLzuOnsKv9MnXCvigmhAgj8bHRjLq5CbXKl2DU7E1sP3CMt/s1pXTxOK9DE5FKD5y9AoYe2JhNy2zldo3Kd47H2W0LIcJEVJSPx66tw8ibG7NyxyF6vrmILfuO5H6iEB7ILVFlnONxdttCiDDTvXFVPrmnOYePp9NzzCIWbd7vdUhCnCXHKZQUzTwNHMXuPRUFMme69AHxlqGGzBTNMoWSEBdux4Fj3DVhGVv3HeVfPRrQt1l1r0MSBeS8p1DygMz1J4QA4PDxUwz+ZCVzf9nHR3c1p3Xtcl6HJApAOCQqWWFNCAFAyfhY3u7XlFrliqNNWc3RE+lehyQEkPeZKS6IopmdsCezjQbGWYZqZDleA3v5+fLAAaCfZahpzrH+wLNO0+ctQ53gZqxCCLsi8OXeydz4zhJemfELerf6XockhHs9KkUzo4ExQGcgCeiraGZSlmbDgYnOSsHDgBedc8sAQ4HmQDNgqKKZpd2KVQjxlxSlDP1bKkxYYpFqyexowntuDv01AzZbhrrVMtST2PMEds/SJgl71Uewp2fKPH4dMMsy1AOWoR4EZmHftyWEKAD/uK4uVUsV5YnPV3P8lMy6LrzlZqKqCuwI2k5z9gVbBdzgPO4JlFQ0s2wezxVCuKR4kRhe7NWQrfuOMnK2LOYtvOXmNarsbgjOWmL4ODBa0cwBwHxgJ/Y6JXk5F0UzBwIDAaKOnryYWIUQWbSpXZ4+KYmMnb+V6xtUpmGizLguvOFmjyoNqBa0nQjsCm5gGeouy1B7WYbaBHjG2RfIy7lO27GWoaZYhppSRqZ/ESLfPaMmUbZ4HP+YvErmBBSecTNRLQNqK5pZU9HMOOx5A6cGN1A0s5yimZkxPIVdAQgwA+ioaGZpp4iio7NPCFGA/EVjeaFnQzbsPszb87Z4HY4opFxLVJahpgODsBPMemCSZahrFc0cpmhmN6dZe+AXRTM3AhWBF5xzDwD/wk52y4BhsjijEN64NqkiXRtV4Y3vN7Fxz2GvwxGFkMxMIYTI1e9HTnDtiPlUK1OMKfdfSXSUzEkdKWRmCiFERChboghDuyaxasch3l+4zetwRCEjiUoIkSfdGlXhmnoVGT7zF6z9R70ORxQikqiEEHni8/l4oWcD4mKiePLz1Zw5ExmXDUTok0QlhMizignxPKvWY+m2A/znx+1ehyMKCUlUblk9CUY0AL2U/X31JK8jEiJf9EmpRutLy/Hi1+vZeehPr8MRhYAkKjesngTTHoLADiDD/j7tIUlWIiL4fD5e7NWQMxnw9JQ1RErlsAhdkqjcMHsYnMrySfPUn/Z+ISJAtTLFeLJTXeZt3MeUFTu9DkdEOElUbgiknd9+IcLQ7S0VUmqUZtj0dew9fNzrcEQEk0TlBn/i+e0XIgxFRfl4qXcyf57D8zKlAAAWLUlEQVQ6zdCv1nodjohgkqjc0OE5iC36932xRe39QkSQS8qX4JFravPNz7v5es1vXocjIpQkKjck94Guo8BfDfDZ37uOsvcLEWEGtqlFg6oJPPfVzxyU5XaEC2SuPyHERVu36w+6jV5It0ZVeO2mxl6HI85DOMz15+bCiUKIQiKpSgIPtL+EUd9vpmujKlx1WQWvQxL5RffHYy9sWwQ7Z0xGDwxF99cEPgXKACuA29ADrnSpZehPCJEvHrz6UmpXKMHTX6zh8PFTXocj8s8J4Gr0QCOgMdAJ3d8CeAkYgR6oDRwE7nIrAElUQoh8USQmmpd7J7Pnj+O8+M0Gr8MR+UUPZKAHjjhbsc5XBnA1MNnZPwHo4VYIMvQnhMg3TaqX5s5WNRm3cBtdk6vQ8pKyXockcjGkZVw5dH/wBf6x6IGxf2uk+6OB5cClwBhgC3AIPZDutEgDqroVo6uJStHMTsBIIBoYZxmqkeV4dexMXMppo1mG+rWimbHAOOByJ8aJlqG+6GasQoj8MaRjXWat34M2ZTXfPtyWonHRXockcvDqkpP7hy8+kXMxhR44DTRG95cCvgDqZdPKtco814b+FM2Mxs68nYEkoK+imUlZmj2LvUR9E+Bm4E1n/41AEctQGwJNgXsVzVTcilUIkX+KxkVj9Erm19+P8erMX7wOR+QnPXAImAu0AEqh+zM7O4nALrde1s1rVM2AzZahbrUM9SR2dUj3LG0ygATnsZ+/ftAMoLiimTFAUeAk8IeLsQoh8lHLS8pya/PqvLdoGyu2H/Q6HHExdH95pycFur8ocA2wHpgD9HZa9Qe+cisEN4f+qgI7grbTgOZZ2ujATEUzBwPFsX8BYF+g6w78BhQDHrUM9UDWF1A0cyAwECBKbjQUIqRonS9jzoa9PDF5NeZDrSkSI0OAYaoyMMG5ThUFTEIPTEf3rwM+Rfc/D6wE3nMrADcTlS+bfVnHMPsC4y1DfVXRzJbAh4pmNsDujZ0GqgClgQWKZn5nGerW4JMtQx0LjAVI+W5oZNy5LESEKBkfywu9GnLHB8sY/f1mhnSs63VI4kLogdVAk2z2b8V+r3adm0N/aUC1oO3sxjDvAiYBWIa6BIgHygG3AN9ahnrKMtS9wCIgpO+cFkKc7aq6FejVpCpvzd3Cul0yei8ujJuJahlQW9HMmopmxmEXS0zN0mY70AFA0cx62Ilqn7P/akUzfYpmFse+cCc3ZggRhp7rmkSpYnHcMzGV79bt8TocEYZcS1SWoaYDg4AZ2BfeJlmGulbRzGGKZnZzmg0B7lE0cxXwCTDAMtQM7GrBEsDP2AnvA8tQV7sVa9iQ5e1FGCpVLI53b29K0bho7p6Yyh0f/Mi2/Ue9DkuEEZmUNlxkLm8fvHJwbFGZlV2EjVOnzzBhscXr323iZPoZ7mlbkwevupRicTLvgJfCYVJamUIpXMjy9iLMxUZHcXebWnw/pB1dkiszZs4WOrw6D3P1b0TKB2bhDklU4UKWtxcRokJCPK/d1Jj/3teSUsXiePA/K7h13FI27TnsdWgiREmiCheyvL2IMFcoZZg+uDX/6l6fn3cG6DxyAc9PXyczr4uzSKIKF24uby9FGsIj0VE+bmupMOfx9tyYksh7i7Zx1fB5TFmRJsOB4n8kUYULt5a3zyzSCOwAMuzv0x6SZCUKVNkSRXixVzJfPtCKqqWL8tikVdz49hLW7gp4HZoIAVL1V9iNaOAkqSz81eDRnws+HlHonTmTweTlabz07QYOHjvJrc1rMKRjHUoVi/M6tIgkVX8i9EmRhggxUVE++lxRje+HtOf2lgofL/2Vq4bP5T9Lt3P6TGR8sBbnRxJVYSdFGiJE+YvFonerj/lQG2pXLMnTX6yh55uLWCmzsRc6kqgKOzeLNITIB/UqJ/DZwBaMvLkxe/44Ts83F/PE5FXsP3LC69BEAZFEVdi5VaQhRD7y+Xx0b1yV2UPac2+7WkxZsZOrhs/lg0XbSD99xuvwhMukmEIIEXY27z3CP6etZcGm/dQqX5x/dKxLpwaV8PmyW11I5ESKKYQQwgWXVijBxDubMfa2pkT5fNz/8Qp6jFnEos37vQ5NuEASlRAiLPl8PjrWr8SMR9rySu9k9h0+wa3jlnLbe0tZnXbI6/BEPpKhPyFERDh+6jQfL93OmDmbOXD0JGrDyjzWsQ6XlC/hdWghLRyG/iRRCSEiyuHjpxi3YBvjFmzlePoZbmyayMPX1Kayv2juJxdChT5RKZrZCRgJRAPjLEM1shyvDkwASjltNMtQv3aOJQPvAAnAGeAKy1CPn+u1JFEJIYLtP3KCMXM28/EP28EHA65UuL/dJZQuLjNcBAuHROXaNSpFM6OxV+rtDCQBfRXNTMrS7FnslX+bYC9V/6ZzbgzwEXCfZaj1gfaATKkshMizciWKMLRrfWYPaUfX5Cq8u2ArbV+ew+jvN3HsZLrX4Ynz4GYxRTNgs2WoWy1DPQl8CnTP0iYDu8cE4Ad2OY87AqstQ10FYBnq75ahnnYxViFEhKpWphiv9mnEtw+3pcUlZRk+cyNtX57LxCUWJ9PlHqxw4GaiqgoEz3aa5uwLpgP9FM1MA74GBjv76wAZimbOUDRzhaKZT7gYpxCiEKhbqSTv3p7C5/dfSa3yxXnuq7V0eG0uX67cyRmZQzCkuZmosrvzLutfQ19gvGWoicD1wIeKZkYBMUBr4Fbne09FMztkfTJFMwcqmpmqaGbqgaMn8zd6cfFknSsBIfd30LRGaT4b2ILxd1xBySKxPPLZT1w/agFzNuyVNbBClJuJKg2oFrSdyF9De5nuAiYBWIa6BIgHyjnnzrMMdb9lqMewe1uXZ30By1DHWoaaYhlqShm5QBpaZJ0rASH7d+Dz+WhftwLTB7dmVN8m/HnqNHeMX8ZN7/xAqnXA09jE2dxMVMuA2opm1lQ0Mw67WGJqljbbgQ4AimbWw05U+4AZQLKimcWcwop2wDoXYxX5bfYwOPXn3/ed+tPeLwqPEP87iIry0a1RFb57rB3P92jAtt+P0vvtJdw1fhkz1u7mz5NyaTwUxLj1xJahpiuaOQg76UQD71uGulbRzGFAqmWoU4EhwLuKZj6KPSw4wDLUDOCgopmvYSe7DOBry1BNt2IVLpB1rgSEzd9BbHQU/VrU4IbLE/lg8TbGzt/K7A17iY+Nok3t8nRMqkiHehWRkRtvyA2/wh2ycrCAsP07OHX6DMu2HWDmuj3MXLubXYHjRPmgWc0ydEyqxLVJFalWppjXYeaLcLiPShKVcEfmtYngYZ/YorKESGHj5t/B6kn2EGIgzV7os8NzrvxtZWRksHbXH8xcu5uZ6/awYfdhwF4nq2NSRTrWr0hS5YSwnbldElUBkkQVgtx4I3HrzamA3vQKJbf+Djz6IPTr70eZtW4PM9fuYdmvB8jIgKqlitKxfkU6JlXiCqU0MdHhM9+3JKoCJImqEHDrzUl6f+EnRIYU9x85wffr9zJz3W7mb9rPyfQzlCoWS4fL7J5W29rlKRoXXWDxXAhJVAVIElUh4NabU4i86YnzoJfi7NsyAXyge7PEx9ET6SzYtI+Za/cwe8NeAn+eCotijFwTle6vBkwEKmHPuzoWPTAS3a8D92BXagM8jR742o0YXav6EyLfuVVBFiaVaSKIP/EcHy4SCz4WR/EiMXRqUJlODSqfVYwxa90eonzQ6tJy/LNbfWqF19Ij6cAQ9MAKdH9JYDm6f5ZzbAR6YLjbAYTPQKoQ53oTutg3J7eeV7inw3P28Gyw2KL2/ouRT7NoxEZHceWl5dC71WeRdjXTB7fmwasuZc3OANePWsDEJVb4TNukB35DD6xwHh8G1nP2dHiukqE/ET7kGpUIlt9FGgXwd7Dnj+M8+flq5v6yjza1y/Fy72TP18l6/Moivw7vGL8/aNdY9MDYbBvrfgWYDzQAHgMGAH8Aqdi9roNuxCiJSoQXqfoTbimga5UZGRl88uMOnjfXER3l41/dG9C9cRXPytvzXEyh+0sA84AX0ANT0P0Vgf3YFwv/BVRGD9zpSoySqIQQggIv0Pj196MMmbSK1F8P0rlBJV7o2dCTYos8JSrdHwtMB2agB17L5rgCTEcPNHAjRrlGJYQQUODXKmuULc5n97ZE63wZs9fvpeOI+cxev8eV17oout8HvAes/1uS0v2Vg1r1BFwrkZWqPyHcJEOK4aPDc9lfo7rYAo0cREf5uK/dJbSrU55HP/uJuyakcvMV1Xi2SxIlioTM23Mr4DZgDbr/J2ff00BfdH9j7G6oBdzrVgAy9CeEW6RII/x4+MHiRPppRn63ibfnbaFKqaK8emMjmtcq6/rryg2/BUgSlQg5ciOxuADLfz3AY5NWsf3AMe5uXZMhHesSH+ve7BbhkKjkGpUQbpEbicUFaFqjDF8/1IZbm1fn3QXb6DZ6IT/vDHgdlqckUQnhlnC7kTjEloyPKOf5uy1eJIbnezRkwp3NCPx5ih5jFvHG7E2knz5TQAGHFklUQrjFrdkT3BCiS8ZHhIv43barU54Zj7Tl+oaVeXXWRnq/vYQt+478/bkLwYcLV69RKZrZCRiJvcLvOMtQjSzHqwMTgFJOG80y1K+zHF8H6Jah5jiflFyjEiEpXKr+5Hqae/Lpdztt1S7+76ufOX7qNE91rsdtxX8kavrFF+sU6mtUimZGA2OAzkAS0FfRzKQszZ4FJlmG2gS4GXgzy/ERwDduxSiE65L72G9G+iH7e34lqfz+JC3X09yTT7/bro2qMOORtrSoVZahU9fy+9Rn/p6kwN6ePewCAw1dbg79NQM2W4a61TLUk8CnQPcsbTKABOexH9iVeUDRzB7AVmCtizEKEX7cGKYLt+tp4SQff7cVE+L5YMAV/LtnQ8qm78u+UQR+uHAzUVUFgvu7aZw9464O9FM0Mw34GhgMoGhmceBJ4J8uxidEeJo9LP8/SYfT9bRwk8+/W5/Pxy3Nq3MmoUr2DSLww4WbiSq7GRazXhDrC4y3DDURuB74UNHMKOwENcIy1CNZnyCYopkDFc1MVTQz9cDRk/kStBAhz41huuQ+9rUNfzXAZ3+XG5Pzh0u/25hrdTIKyYcLN+foSAOqBW0nEjS057gL6ARgGeoSRTPjgXJAc6C3opkvYxdanFE087hlqKODT7YMdSwwFiDlu6GRceeyELlxa9HA5D6SmNzixu82uY/dGwiHYp2L5GaiWgbUVjSzJrATu1jilixttgMdgPGKZtYD4oF9lqG2yWygaKYOHMmapIQotDyYk06EqELy4cK1oT/LUNOBQcAM7BUhJ1mGulbRzGGKZnZzmg0B7lE0cxXwCTDAMlTpGQmRExmmE4WMzPUnhBCFWKG+j0oIIYTID5KohBBChDRJVEIIIUKaJCohhBAhTRKVEEKIkBYxVX8+n28f8OuFnh9VrFS5M8cO7c/HkFwTTrFCeMUbTrFCeMUbTrFCeMV7kbHWyMjIKJ+vAeW3jIwM+crIoMaT01O9jiESYw23eMMp1nCLN5xiDbd4wynWC/mSoT8hhBAhTRKVEEKIkCaJ6i9jvQ7gPIRTrBBe8YZTrBBe8YZTrBBe8YZTrOctYoophBBCRCbpUQkhhAhpbi7zERYUzewEjASigXGWoRoeh3ROimZWAyYClYAzwFjLUEd6G1XOFM2MBlKBnZahdvE6npwomlkKGAc0wF7k807LUJd4G1X2FM18FLgbO841wB2WoR73Nqq/KJr5PtAF2GsZagNnXxngM0ABLKCPZagHvYox0zlifQXoCpwEtmD/fg95F+Vfsos36NjjwCtAectQw6K0Pi8KdY/KeRMdA3QGkoC+imYmeRtVjtKBIZah1gNaAA+GeLwAD2Mv8xIORgLfWoZ6GdCIEI1b0cyqwENAivNGFY293lsoGY+zKGoQDZhtGWptYLazHQrGc3ass4AGlqEmAxuBpwo6qByM5+x4Mz/IXou9zl9EKdSJCmgGbLYMdatlqCeBT4HuHsd0Tpah/mYZ6grn8WHsN9Kq3kZ1bopmJgIqdi8lpCmamQC0Bd4DsAz1ZKh8gj6HGKCoopkxQDHOXj3bU5ahzgcOZNndHZjgPJ4A9CjQoM4hu1gtQ53prKkH8AP2CuUh4Ry/W4ARwBPYveyIUtgTVVUgeE3vNEL4jT+YopkK0ARY6nEoOXkd+x/njNeB5EEtYB/wgaKZKxXNHKdoZnGvg8qOZag7geHYn5x/AwKWoc70Nqo8qWgZ6m9gf+gCKngcT17dCXzjdRA5cRaj3WkZ6iqvY3FDYU9Uvmz2hfynEUUzSwCfA49YhvqH1/FkR9HMzDH05V7HkkcxwOXAW5ahNgGOEjpDU3+jaGZp7N5JTaAKUFzRzH7eRhWZFM18BnvI/WOvYzkXRTOLAc8Az3kdi1sKe6JKA6oFbScSYkMoWSmaGYudpD62DHWK1/HkoBXQTdFMC3tI9WpFMz/yNqQcpQFplqFm9lAnYyeuUHQNsM0y1H2WoZ4CpgBXehxTXuxRNLMygPN9r8fx5EjRzP7YRQu3WoYayh9gL8H+0LLK+X9LBFYomlnJ06jyUWGv+lsG1FY0syawE/uC9C3ehnRuimb6sK+hrLcM9TWv48mJZahP4VyAVjSzPfC4Zagh+6nfMtTdimbuUDSzrmWovwAdgHVex3UO24EWzifpP7FjTfU2pDyZCvQHDOf7V96Gc25ONfCTQDvLUI95HU9OLENdQ9AwqpOsUiKp6q9QJyrLUNMVzRwEzMCunHrfMtS1HoeVk1bAbcAaRTN/cvY9bRnq1x7GFEkGAx8rmhkHbAXu8DiebFmGulTRzMnACuxhqZWE2MwEimZ+ArQHyimamQYMxU5QkxTNvAs72d7oXYR/OUesTwFFgFmKZgL8YBnqfZ4FGSS7eC1Dfc/bqNwlM1MIIYQIaYX9GpUQQogQJ4lKCCFESJNEJYQQIqRJohJCCBHSJFEJIYQIaYW6PF2IC6FoZkXsedVaAAexZ9h+2TLULzwNTIgIJT0qIc6Dc9P1l8B8y1BrWYbaFPtG8ZCZtFSISCP3UQlxHhTN7AA8Zxlqu2yOKcCHQOZktoMsQ13szMzxT2AP0Bh7yqM12EugFAV6WIa6RdHM8sDbQHXn/EcsQ13k4o8jRFiQHpUQ56c+9owQ2dkLXGsZ6uXATcCooGONsBNTQ+zZRepYhtoMewmUwU6bkcAIy1CvAG4gDJZHEaIgyDUqIS6CopljgNbY16muAUYrmtkYOA3UCWq6LHOJC0UztwCZy3KsAa5yHl8DJDlT9gAkKJpZ0ll7TIhCSxKVEOdnLXZvBwDLUB9UNLMc9qSwj2IP7zXCHq0IXhr+RNDjM0HbZ/jr/zAKaGkZ6p/uhC5EeJKhPyHOz/dAvKKZ9wftK+Z89wO/WYZ6Bnt4L/o8n3smMChzw+mZCVHoSY9KiPNgGWqGopk9gBGKZj6BvSrwUewlIVYAnyuaeSMwx9l/Ph4CxiiauRr7f3M+EBIzdgvhJan6E0IIEdJk6E8IIURIk0QlhBAipEmiEkIIEdIkUQkhhAhpkqiEEEKENElUQgghQpokKiGEECFNEpUQQoiQ9v86U1syuUecdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plotLearning(np.arange(len(scores)), scores, eps_history, filename)\n",
    "\n",
    "done = False\n",
    "score=0\n",
    "observation = env.reset()\n",
    "while not done:\n",
    "    env.render()\n",
    "    action = agent.choose_action(observation)\n",
    "    observation_, reward, done, info = env.step(action)\n",
    "    score += reward\n",
    "\n",
    "    agent.store_transition(observation, action, reward, observation_, done)\n",
    "    agent.learn()\n",
    "    observation = observation_\n",
    "env.close()\n",
    "print(f'Score is:{score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_more(n_games=50, avg_to_break = 350):\n",
    "    for i in range(n_games):\n",
    "        score = 0\n",
    "        done = False\n",
    "        observation = env.reset()\n",
    "        while not done:\n",
    "\n",
    "            action = agent.choose_action(observation)\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "            agent.store_transition(observation, action, reward, observation_, done)\n",
    "            agent.learn()\n",
    "            observation = observation_\n",
    "        scores.append(score)\n",
    "        eps_history.append(agent.epsilon)\n",
    "        avg_score = np.mean(scores[-10:])\n",
    "        print('episode ', i, 'score %.2f' % score, 'average score %.2f' % avg_score, 'epsilon %.2f' % agent.epsilon)\n",
    "        if avg_score > avg_to_break:\n",
    "            return # same as break\n",
    "    \n",
    "train_more(n_games=30, avg_to_break = 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(agent, open(f'agent_CartPole-v1_{len(scores)}.p', \"wb\" ))\n",
    "\n",
    "# agent = pickle.load(open(\"agent_LunarLander-v2_400.p\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
