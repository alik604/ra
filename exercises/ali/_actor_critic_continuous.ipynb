{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor Critic Continuous\n",
    "> by Khizr Ali Pardhan | Alik604\n",
    "\n",
    "Apprently Actor Critic low-key sucks compared to other Policy Gradient algos, such as DDPG\n",
    "\n",
    "Hence, I'm just running this for Amusement and practice reading code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import plotLearning\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = pickle.load(open(\"_actor_crt_mountaincar_con-1.2488451868607289_epoch103.p\",'rb'))\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "score_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericNetwork(nn.Module):\n",
    "    def __init__(self, alpha, input_dims, fc1_dims, fc2_dims,\n",
    "                 n_actions):\n",
    "        super(GenericNetwork, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
    "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        self.fc3 = nn.Linear(self.fc2_dims, self.n_actions)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cuda:1')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, observation):\n",
    "        state = T.tensor(observation, dtype=T.float).to(self.device)\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, alpha, beta, input_dims, gamma=0.99, n_actions=2,\n",
    "                 layer1_size=256, layer2_size=256, n_outputs=1):\n",
    "        self.gamma = gamma\n",
    "        self.log_probs = None\n",
    "        self.n_outputs = n_outputs\n",
    "        self.actor = GenericNetwork(alpha, input_dims, layer1_size,\n",
    "                                           layer2_size, n_actions=n_actions)\n",
    "        self.critic = GenericNetwork(beta, input_dims, layer1_size,\n",
    "                                            layer2_size, n_actions=1)\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        mu, sigma  = self.actor.forward(observation)#.to(self.actor.device)\n",
    "        sigma = T.exp(sigma)\n",
    "        action_probs = T.distributions.Normal(mu, sigma)\n",
    "        probs = action_probs.sample(sample_shape=T.Size([self.n_outputs]))\n",
    "        self.log_probs = action_probs.log_prob(probs).to(self.actor.device)\n",
    "        action = T.tanh(probs)\n",
    "\n",
    "        return action.item()\n",
    "\n",
    "    def learn(self, state, reward, new_state, done):\n",
    "        self.actor.optimizer.zero_grad()\n",
    "        self.critic.optimizer.zero_grad()\n",
    "\n",
    "        critic_value_ = self.critic.forward(new_state)\n",
    "        critic_value = self.critic.forward(state)\n",
    "        reward = T.tensor(reward, dtype=T.float).to(self.actor.device)\n",
    "        delta = ((reward + self.gamma*critic_value_*(1-int(done))) - \\\n",
    "                                                                critic_value)\n",
    "\n",
    "        actor_loss = -self.log_probs * delta\n",
    "        critic_loss = delta**2\n",
    "\n",
    "        (actor_loss + critic_loss).backward()\n",
    "\n",
    "        self.actor.optimizer.step()\n",
    "        self.critic.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0 score: -24.69\n",
      "episode:  1 score: -4.15\n",
      "episode:  2 score: -1.34\n",
      "episode:  3 score: -0.52\n",
      "episode:  4 score: -0.31\n",
      "episode:  5 score: -1.77\n",
      "episode:  6 score: -12.08\n",
      "episode:  7 score: -0.46\n",
      "episode:  8 score: -1.11\n",
      "episode:  9 score: -6.18\n",
      "episode:  10 score: -3.40\n",
      "episode:  11 score: -10.91\n",
      "episode:  12 score: -11.28\n",
      "episode:  13 score: -0.47\n",
      "episode:  14 score: -0.07\n",
      "episode:  15 score: -4.46\n",
      "episode:  16 score: -14.04\n",
      "episode:  17 score: -6.41\n",
      "episode:  18 score: -0.11\n",
      "episode:  19 score: -1.96\n",
      "episode:  20 score: -4.45\n",
      "episode:  21 score: -9.26\n",
      "episode:  22 score: -15.57\n",
      "episode:  23 score: -23.81\n",
      "episode:  24 score: -22.47\n",
      "episode:  25 score: -28.60\n",
      "episode:  26 score: -20.19\n",
      "episode:  27 score: -7.56\n",
      "episode:  28 score: -10.53\n",
      "episode:  29 score: -14.63\n",
      "episode:  30 score: -3.69\n",
      "episode:  31 score: -7.72\n",
      "episode:  32 score: -18.50\n",
      "episode:  33 score: -24.13\n",
      "episode:  34 score: -36.24\n",
      "episode:  35 score: -24.12\n",
      "episode:  36 score: -17.80\n",
      "episode:  37 score: -9.43\n",
      "episode:  38 score: -25.60\n",
      "episode:  39 score: -18.33\n",
      "episode:  40 score: -26.08\n",
      "episode:  41 score: -39.28\n",
      "episode:  42 score: -35.31\n",
      "episode:  43 score: -38.77\n",
      "episode:  44 score: -39.68\n",
      "episode:  45 score: -43.60\n",
      "episode:  46 score: -32.54\n",
      "episode:  47 score: -29.97\n",
      "episode:  48 score: -46.06\n",
      "episode:  49 score: -58.04\n",
      "episode:  50 score: -66.55\n",
      "episode:  51 score: -67.16\n",
      "episode:  52 score: -56.72\n",
      "episode:  53 score: -63.26\n",
      "episode:  54 score: -71.07\n",
      "episode:  55 score: -73.73\n",
      "episode:  56 score: -63.21\n",
      "episode:  57 score: -52.61\n",
      "episode:  58 score: -63.11\n",
      "episode:  59 score: -70.92\n",
      "episode:  60 score: -58.43\n",
      "episode:  61 score: -66.10\n",
      "episode:  62 score: -72.24\n",
      "episode:  63 score: -80.32\n",
      "episode:  64 score: -83.24\n",
      "episode:  65 score: -78.80\n",
      "episode:  66 score: -71.34\n",
      "episode:  67 score: -55.65\n",
      "episode:  68 score: -60.05\n",
      "episode:  69 score: -58.29\n",
      "episode:  70 score: -65.01\n",
      "episode:  71 score: -57.72\n",
      "episode:  72 score: -56.16\n",
      "episode:  73 score: -58.33\n",
      "episode:  74 score: -67.34\n",
      "episode:  75 score: -69.30\n",
      "episode:  76 score: -79.27\n",
      "episode:  77 score: -89.78\n",
      "episode:  78 score: -86.31\n",
      "episode:  79 score: -86.33\n",
      "episode:  80 score: -89.54\n",
      "episode:  81 score: -93.09\n",
      "episode:  82 score: -94.72\n",
      "episode:  83 score: -88.07\n",
      "episode:  84 score: -91.56\n",
      "episode:  85 score: -93.73\n",
      "episode:  86 score: -96.57\n",
      "episode:  87 score: -97.73\n",
      "episode:  88 score: -97.15\n",
      "episode:  89 score: -95.10\n",
      "episode:  90 score: -93.76\n",
      "episode:  91 score: -93.41\n",
      "episode:  92 score: -90.47\n",
      "episode:  93 score: -91.63\n",
      "episode:  94 score: -91.06\n",
      "episode:  95 score: -92.28\n",
      "episode:  96 score: -88.08\n",
      "episode:  97 score: -86.66\n",
      "episode:  98 score: -77.78\n",
      "episode:  99 score: -73.44\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(alpha=0.0005, beta=0.0001, input_dims=[2], gamma=0.99,\n",
    "# agent = Agent(alpha=0.000005, beta=0.00001, input_dims=[2], gamma=0.99,\n",
    "              layer1_size=16, layer2_size=16)\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "score_history = []\n",
    "num_episodes = 100\n",
    "for i in range(num_episodes):\n",
    "    #env = wrappers.Monitor(env, \"tmp/mountaincar-continuous-trained-1\",\n",
    "    #                        video_callable=lambda episode_id: True, force=True)\n",
    "    done = False\n",
    "    score = 0\n",
    "    observation = env.reset()\n",
    "    while not done:\n",
    "        action = np.array(agent.choose_action(observation)).reshape((1,))\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        agent.learn(observation, reward, observation_, done)\n",
    "        observation = observation_\n",
    "        score += reward\n",
    "    score_history.append(score)\n",
    "    print('episode: ', i,'score: %.2f' % score)\n",
    "filename = 'mountaincar-continuous-old-actor-critic-100games.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fbfb301e08>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(score_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0 score: -0.46\n"
     ]
    }
   ],
   "source": [
    "def demo(n_demos=1):\n",
    "    for i in range(n_demos):\n",
    "        done = False\n",
    "        score = 0\n",
    "        observation = env.reset()\n",
    "        while not done:\n",
    "            action = np.array(agent.choose_action(observation)).reshape((1,))\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "        #     agent.learn(observation, reward, observation_, done)\n",
    "            observation = observation_\n",
    "            score += reward\n",
    "            env.render()\n",
    "        score_history.append(score)\n",
    "        print('episode: ', i,'score: %.2f' % score)\n",
    "        env.close()\n",
    "        \n",
    "demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0 score: -0.69\n",
      "episode:  1 score: -0.71\n",
      "episode:  2 score: -0.71\n",
      "episode:  3 score: -0.73\n",
      "episode:  4 score: -0.62\n",
      "episode:  5 score: -0.61\n",
      "episode:  6 score: -0.61\n",
      "episode:  7 score: -0.55\n",
      "episode:  8 score: -0.58\n",
      "episode:  9 score: -0.55\n",
      "episode:  10 score: -0.51\n",
      "episode:  11 score: -0.49\n",
      "episode:  12 score: -0.51\n",
      "episode:  13 score: -0.50\n",
      "episode:  14 score: -0.51\n",
      "episode:  15 score: -0.49\n",
      "episode:  16 score: -0.48\n",
      "episode:  17 score: -0.55\n",
      "episode:  18 score: -0.52\n",
      "episode:  19 score: -0.48\n",
      "episode:  20 score: -0.49\n",
      "episode:  21 score: -0.54\n",
      "episode:  22 score: -0.51\n",
      "episode:  23 score: -0.51\n",
      "episode:  24 score: -0.47\n",
      "episode:  25 score: -0.49\n",
      "episode:  26 score: -0.49\n",
      "episode:  27 score: -0.46\n",
      "episode:  28 score: -0.51\n",
      "episode:  29 score: -0.45\n",
      "episode:  30 score: -0.44\n",
      "episode:  31 score: -0.46\n",
      "episode:  32 score: -0.46\n",
      "episode:  33 score: -0.45\n",
      "episode:  34 score: -0.44\n",
      "episode:  35 score: -0.44\n",
      "episode:  36 score: -0.46\n",
      "episode:  37 score: -0.49\n",
      "episode:  38 score: -0.44\n",
      "episode:  39 score: -0.47\n",
      "episode:  40 score: -0.42\n",
      "episode:  41 score: -0.40\n",
      "episode:  42 score: -0.43\n",
      "episode:  43 score: -0.44\n",
      "episode:  44 score: -0.48\n",
      "episode:  45 score: -0.44\n",
      "episode:  46 score: -0.42\n",
      "episode:  47 score: -0.41\n",
      "episode:  48 score: -0.42\n",
      "episode:  49 score: -0.42\n",
      "episode:  50 score: -0.47\n",
      "episode:  51 score: -0.48\n",
      "episode:  52 score: -0.52\n",
      "episode:  53 score: -0.53\n",
      "episode:  54 score: -0.45\n",
      "episode:  55 score: -0.43\n",
      "episode:  56 score: -0.45\n",
      "episode:  57 score: -0.40\n",
      "episode:  58 score: -0.38\n",
      "episode:  59 score: -0.39\n",
      "episode:  60 score: -0.34\n",
      "episode:  61 score: -0.38\n",
      "episode:  62 score: -0.37\n",
      "episode:  63 score: -0.37\n",
      "episode:  64 score: -0.40\n",
      "episode:  65 score: -0.45\n",
      "episode:  66 score: -0.42\n",
      "episode:  67 score: -0.42\n",
      "episode:  68 score: -0.41\n",
      "episode:  69 score: -0.45\n",
      "episode:  70 score: -0.51\n",
      "episode:  71 score: -0.53\n",
      "episode:  72 score: -0.47\n",
      "episode:  73 score: -0.53\n",
      "episode:  74 score: -0.44\n",
      "episode:  75 score: -0.38\n",
      "episode:  76 score: -0.37\n",
      "episode:  77 score: -0.32\n",
      "episode:  78 score: -0.36\n",
      "episode:  79 score: -0.37\n",
      "episode:  80 score: -0.35\n",
      "episode:  81 score: -0.33\n",
      "episode:  82 score: -0.34\n",
      "episode:  83 score: -0.33\n",
      "episode:  84 score: -0.33\n",
      "episode:  85 score: -0.33\n",
      "episode:  86 score: -0.32\n",
      "episode:  87 score: -0.32\n",
      "episode:  88 score: -0.37\n",
      "episode:  89 score: -0.36\n",
      "episode:  90 score: -0.45\n",
      "episode:  91 score: -0.46\n",
      "episode:  92 score: -0.41\n",
      "episode:  93 score: -0.49\n",
      "episode:  94 score: -0.43\n",
      "episode:  95 score: -0.43\n",
      "episode:  96 score: -0.47\n",
      "episode:  97 score: -0.57\n",
      "episode:  98 score: -0.55\n",
      "episode:  99 score: -0.43\n"
     ]
    }
   ],
   "source": [
    "def train_more(n_games=100):\n",
    "    for i in range(n_games):\n",
    "        done = False\n",
    "        score = 0\n",
    "        observation = env.reset()\n",
    "        while not done:\n",
    "            action = np.array(agent.choose_action(observation)).reshape((1,))\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            agent.learn(observation, reward, observation_, done)\n",
    "            observation = observation_\n",
    "            score += reward\n",
    "        score_history.append(score)\n",
    "        print('episode: ', i,'score: %.2f' % score)\n",
    "    \n",
    "    if score > 50:\n",
    "        pickle.dump(agent, open(f'_actor_crt_mountaincar_con{score}_epoch{len(score_history)}.p', \"wb\" ))   \n",
    "            \n",
    "train_more(n_games=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.alpha=0.000005\n",
    "# agent.beta=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(agent, open(f'_actor_crt_mountaincar_con{score}_epoch{len(score_history)}.p', \"wb\" ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0 score: -9.50\n",
      "episode:  1 score: -5.72\n",
      "episode:  2 score: -2.36\n",
      "episode:  3 score: -1.89\n",
      "episode:  4 score: -5.06\n",
      "episode:  5 score: -2.09\n",
      "episode:  6 score: -19.83\n",
      "episode:  7 score: -28.01\n",
      "episode:  8 score: -46.94\n",
      "episode:  9 score: -26.58\n",
      "episode:  10 score: -64.17\n",
      "episode:  11 score: -31.94\n",
      "episode:  12 score: -4.70\n",
      "episode:  13 score: -5.20\n",
      "episode:  14 score: -11.67\n",
      "episode:  15 score: -2.25\n",
      "episode:  16 score: -2.27\n",
      "episode:  17 score: -1.02\n",
      "episode:  18 score: -3.95\n",
      "episode:  19 score: -4.93\n",
      "episode:  20 score: -9.71\n",
      "episode:  21 score: -7.80\n",
      "episode:  22 score: -4.23\n",
      "episode:  23 score: -5.26\n",
      "episode:  24 score: -2.09\n",
      "episode:  25 score: -13.90\n",
      "episode:  26 score: -3.62\n",
      "episode:  27 score: -4.04\n",
      "episode:  28 score: -4.21\n",
      "episode:  29 score: -5.84\n",
      "episode:  30 score: -2.25\n",
      "episode:  31 score: -3.08\n",
      "episode:  32 score: -2.27\n",
      "episode:  33 score: -3.04\n",
      "episode:  34 score: -8.44\n",
      "episode:  35 score: -0.71\n",
      "episode:  36 score: -3.01\n",
      "episode:  37 score: -2.83\n",
      "episode:  38 score: -4.28\n",
      "episode:  39 score: -20.46\n",
      "episode:  40 score: -6.57\n",
      "episode:  41 score: -4.39\n",
      "episode:  42 score: -3.34\n",
      "episode:  43 score: -9.26\n",
      "episode:  44 score: -3.59\n",
      "episode:  45 score: -4.63\n",
      "episode:  46 score: -13.68\n",
      "episode:  47 score: -12.29\n",
      "episode:  48 score: -18.35\n",
      "episode:  49 score: -45.06\n",
      "episode:  50 score: -61.01\n",
      "episode:  51 score: -76.93\n",
      "episode:  52 score: -59.06\n",
      "episode:  53 score: -62.46\n",
      "episode:  54 score: -58.44\n",
      "episode:  55 score: -42.46\n",
      "episode:  56 score: -34.48\n",
      "episode:  57 score: -28.71\n",
      "episode:  58 score: -42.62\n",
      "episode:  59 score: -62.37\n",
      "episode:  60 score: -75.50\n",
      "episode:  61 score: -85.28\n",
      "episode:  62 score: -83.68\n",
      "episode:  63 score: -98.76\n",
      "episode:  64 score: -98.92\n",
      "episode:  65 score: -98.40\n",
      "episode:  66 score: -96.03\n",
      "episode:  67 score: -97.13\n",
      "episode:  68 score: -99.17\n",
      "episode:  69 score: -99.50\n",
      "episode:  70 score: -98.80\n",
      "episode:  71 score: -99.57\n",
      "episode:  72 score: -98.77\n",
      "episode:  73 score: -98.83\n",
      "episode:  74 score: -98.03\n",
      "episode:  75 score: -95.48\n",
      "episode:  76 score: -89.63\n",
      "episode:  77 score: -83.98\n",
      "episode:  78 score: -84.92\n",
      "episode:  79 score: -82.47\n",
      "episode:  80 score: -79.29\n",
      "episode:  81 score: -75.69\n",
      "episode:  82 score: -80.18\n",
      "episode:  83 score: -86.22\n",
      "episode:  84 score: -61.47\n",
      "episode:  85 score: -70.52\n",
      "episode:  86 score: -56.81\n",
      "episode:  87 score: -50.37\n",
      "episode:  88 score: -58.43\n",
      "episode:  89 score: -84.53\n",
      "episode:  90 score: -90.74\n",
      "episode:  91 score: -91.66\n",
      "episode:  92 score: -77.38\n",
      "episode:  93 score: -75.16\n",
      "episode:  94 score: -76.94\n",
      "episode:  95 score: -88.48\n",
      "episode:  96 score: -92.14\n",
      "episode:  97 score: -91.78\n",
      "episode:  98 score: -82.87\n",
      "episode:  99 score: -93.64\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(alpha=0.005, beta=0.001, input_dims=[2], gamma=0.99,\n",
    "# agent = Agent(alpha=0.000005, beta=0.00001, input_dims=[2], gamma=0.99,\n",
    "              layer1_size=16, layer2_size=16)\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "score_history = []\n",
    "num_episodes = 100\n",
    "for i in range(num_episodes):\n",
    "    #env = wrappers.Monitor(env, \"tmp/mountaincar-continuous-trained-1\",\n",
    "    #                        video_callable=lambda episode_id: True, force=True)\n",
    "    done = False\n",
    "    score = 0\n",
    "    observation = env.reset()\n",
    "    while not done:\n",
    "        action = np.array(agent.choose_action(observation)).reshape((1,))\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        agent.learn(observation, reward, observation_, done)\n",
    "        observation = observation_\n",
    "        score += reward\n",
    "    score_history.append(score)\n",
    "    print('episode: ', i,'score: %.2f' % score)\n",
    "filename = 'mountaincar-continuous-old-actor-critic-100games.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0 score: -5.61\n",
      "episode:  1 score: -13.46\n",
      "episode:  2 score: -5.97\n",
      "episode:  3 score: -13.25\n",
      "episode:  4 score: -15.61\n",
      "episode:  5 score: -4.34\n",
      "episode:  6 score: -19.91\n",
      "episode:  7 score: -11.44\n",
      "episode:  8 score: -6.09\n",
      "episode:  9 score: -4.15\n",
      "episode:  10 score: -14.35\n",
      "episode:  11 score: -28.24\n",
      "episode:  12 score: -24.11\n",
      "episode:  13 score: -14.26\n",
      "episode:  14 score: -11.57\n",
      "episode:  15 score: -5.62\n",
      "episode:  16 score: -7.24\n",
      "episode:  17 score: -7.35\n",
      "episode:  18 score: -10.86\n",
      "episode:  19 score: -9.59\n",
      "episode:  20 score: -1.46\n",
      "episode:  21 score: -3.40\n",
      "episode:  22 score: -1.26\n",
      "episode:  23 score: -8.49\n",
      "episode:  24 score: -17.36\n",
      "episode:  25 score: -5.50\n",
      "episode:  26 score: -2.98\n",
      "episode:  27 score: -7.09\n",
      "episode:  28 score: -1.15\n",
      "episode:  29 score: -8.28\n",
      "episode:  30 score: -49.13\n",
      "episode:  31 score: -4.80\n",
      "episode:  32 score: -28.69\n",
      "episode:  33 score: -76.67\n",
      "episode:  34 score: -83.80\n",
      "episode:  35 score: -95.89\n",
      "episode:  36 score: -98.59\n",
      "episode:  37 score: -91.77\n",
      "episode:  38 score: -99.03\n",
      "episode:  39 score: -99.89\n",
      "episode:  40 score: -99.90\n",
      "episode:  41 score: -99.89\n",
      "episode:  42 score: -99.81\n",
      "episode:  43 score: -99.26\n",
      "episode:  44 score: -99.41\n",
      "episode:  45 score: -99.22\n",
      "episode:  46 score: -99.53\n",
      "episode:  47 score: -98.33\n",
      "episode:  48 score: -98.72\n",
      "episode:  49 score: -96.85\n",
      "episode:  50 score: -93.37\n",
      "episode:  51 score: -98.58\n",
      "episode:  52 score: -98.86\n",
      "episode:  53 score: -92.37\n",
      "episode:  54 score: -91.16\n",
      "episode:  55 score: -90.13\n",
      "episode:  56 score: -76.09\n",
      "episode:  57 score: -72.69\n",
      "episode:  58 score: -45.66\n",
      "episode:  59 score: -48.18\n",
      "episode:  60 score: -62.54\n",
      "episode:  61 score: -86.12\n",
      "episode:  62 score: -68.01\n",
      "episode:  63 score: -80.96\n",
      "episode:  64 score: -54.54\n",
      "episode:  65 score: -32.63\n",
      "episode:  66 score: -49.03\n",
      "episode:  67 score: -29.22\n",
      "episode:  68 score: -13.70\n",
      "episode:  69 score: -7.04\n",
      "episode:  70 score: -5.25\n",
      "episode:  71 score: -9.16\n",
      "episode:  72 score: -4.45\n",
      "episode:  73 score: -5.68\n",
      "episode:  74 score: -8.52\n",
      "episode:  75 score: -1.36\n",
      "episode:  76 score: -2.91\n",
      "episode:  77 score: -4.94\n",
      "episode:  78 score: -6.84\n",
      "episode:  79 score: -3.57\n",
      "episode:  80 score: -27.21\n",
      "episode:  81 score: -30.29\n",
      "episode:  82 score: -39.64\n",
      "episode:  83 score: -39.99\n",
      "episode:  84 score: -13.54\n",
      "episode:  85 score: -4.35\n",
      "episode:  86 score: -5.48\n",
      "episode:  87 score: -58.33\n",
      "episode:  88 score: -47.41\n",
      "episode:  89 score: -20.80\n",
      "episode:  90 score: -2.72\n",
      "episode:  91 score: -1.23\n",
      "episode:  92 score: -2.09\n",
      "episode:  93 score: -0.16\n",
      "episode:  94 score: -0.56\n",
      "episode:  95 score: -1.66\n",
      "episode:  96 score: -37.90\n",
      "episode:  97 score: -3.59\n",
      "episode:  98 score: -30.46\n",
      "episode:  99 score: -82.18\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(alpha=0.0005, beta=0.0001, input_dims=[2], gamma=0.99,\n",
    "# agent = Agent(alpha=0.000005, beta=0.00001, input_dims=[2], gamma=0.99,\n",
    "              layer1_size=160, layer2_size=160)\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "score_history = []\n",
    "num_episodes = 100\n",
    "for i in range(num_episodes):\n",
    "    #env = wrappers.Monitor(env, \"tmp/mountaincar-continuous-trained-1\",\n",
    "    #                        video_callable=lambda episode_id: True, force=True)\n",
    "    done = False\n",
    "    score = 0\n",
    "    observation = env.reset()\n",
    "    while not done:\n",
    "        action = np.array(agent.choose_action(observation)).reshape((1,))\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        agent.learn(observation, reward, observation_, done)\n",
    "        observation = observation_\n",
    "        score += reward\n",
    "    score_history.append(score)\n",
    "    print('episode: ', i,'score: %.2f' % score)\n",
    "filename = 'mountaincar-continuous-old-actor-critic-100games.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = Agent(alpha=0.0005, beta=0.0001, input_dims=[2], gamma=0.99,\n",
    "agent = Agent(alpha=0.000005, beta=0.00001, input_dims=[2], gamma=0.99,\n",
    "              layer1_size=160, layer2_size=160)\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "score_history = []\n",
    "num_episodes = 100\n",
    "for i in range(num_episodes):\n",
    "    #env = wrappers.Monitor(env, \"tmp/mountaincar-continuous-trained-1\",\n",
    "    #                        video_callable=lambda episode_id: True, force=True)\n",
    "    done = False\n",
    "    score = 0\n",
    "    observation = env.reset()\n",
    "    while not done:\n",
    "        action = np.array(agent.choose_action(observation)).reshape((1,))\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        agent.learn(observation, reward, observation_, done)\n",
    "        observation = observation_\n",
    "        score += reward\n",
    "    score_history.append(score)\n",
    "    print('episode: ', i,'score: %.2f' % score)\n",
    "filename = 'mountaincar-continuous-old-actor-critic-100games.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
