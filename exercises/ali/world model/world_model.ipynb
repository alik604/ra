{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twin Delayed Deep Deterministic Policy Gradients (TD3)\n",
    "> Alik604\n",
    "\n",
    "Twin Delayed Deep Deterministic Policy Gradients (TD3) is a state of the art actor critic algorithm for mastering environments with continuous action spaces. It's based on the deep deterministic policy gradients algorithm, but deals with the problem of overestimation bias that arises from the use of deep neural networks as function approximators.\n",
    "\n",
    "### Source \n",
    "[Video](https://www.youtube.com/watch?v=1lZOB2S17LU)\n",
    "[code](https://github.com/philtabor/Youtube-Code-Repository/tree/master/ReinforcementLearning/PolicyGradient/TD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "import gym\n",
    "from torch import nn, optim, distributions\n",
    "from torch.nn import functional as F\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "from torch import optim, distributions\n",
    "from tqdm import tqdm\n",
    "#from es import EvolutionStrategy\n",
    "#from bipedal_walker import BipedalWalker\n",
    "#from pop import Population, rollout\n",
    "#from utils import ValueLogger\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "from cma import CMAEvolutionStrategy\n",
    "\n",
    "\n",
    "class EvolutionStrategy:\n",
    "  # Wrapper for CMAEvolutionStrategy\n",
    "  def __init__(self, mu, sigma, popsize, weight_decay=0.01):\n",
    "    self.es = CMAEvolutionStrategy(mu.tolist(), sigma, {'popsize': popsize})\n",
    "    self.weight_decay = weight_decay\n",
    "    self.solutions = None\n",
    "\n",
    "  @property\n",
    "  def best(self):\n",
    "    best_sol = self.es.result[0]\n",
    "    best_fit = -self.es.result[1]\n",
    "    return best_sol, best_fit\n",
    "\n",
    "  def _compute_weight_decay(self, model_param_list):\n",
    "    model_param_grid = np.array(model_param_list)\n",
    "    return -self.weight_decay * np.mean(model_param_grid * model_param_grid, axis=1)\n",
    "\n",
    "  def ask(self):\n",
    "    self.solutions = self.es.ask()\n",
    "    return self.solutions\n",
    "\n",
    "  def tell(self, reward_table_result):\n",
    "    reward_table = -np.array(reward_table_result)\n",
    "    if self.weight_decay > 0:\n",
    "      l2_decay = self._compute_weight_decay(self.solutions)\n",
    "      reward_table += l2_decay\n",
    "    self.es.tell(self.solutions, reward_table.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorldModel(nn.Module):\n",
    "  def __init__(self, obs_dim, act_dim, hid_dim=64):\n",
    "    super(WorldModel, self).__init__()\n",
    "    self.obs_dim = obs_dim\n",
    "    self.act_dim = act_dim \n",
    "    self.hid_dim = hid_dim\n",
    "\n",
    "    self.lstm = nn.LSTMCell(obs_dim+act_dim, hid_dim)\n",
    "    self.mu = nn.Linear(hid_dim, obs_dim)\n",
    "    self.logsigma = nn.Linear(hid_dim, obs_dim)\n",
    "\n",
    "  def forward(self, obs, act, hid):\n",
    "    x = pt.cat([obs, act], dim=-1)\n",
    "    h, c = self.lstm(x, hid)\n",
    "    mu = self.mu(h)\n",
    "    sigma = pt.exp(self.logsigma(h))\n",
    "    return mu, sigma, (h, c)\n",
    "\n",
    "class Phenotype(nn.Module):\n",
    "  @property\n",
    "  def genotype(self):\n",
    "    params = [p.detach().view(-1) for p in self.parameters()]\n",
    "    return pt.cat(params, dim=0).cpu().numpy()\n",
    "\n",
    "  def load_genotype(self, params):\n",
    "    start = 0\n",
    "    for p in self.parameters():\n",
    "      end = start + p.numel()\n",
    "      new_p = pt.from_numpy(params[start:end])\n",
    "      p.data.copy_(new_p.view(p.shape).to(p.device))\n",
    "      start = end\n",
    "\n",
    "class Controller(Phenotype, nn.Linear):\n",
    "  def forward(self, obs, h):\n",
    "    state = pt.cat([obs, h], dim=-1)\n",
    "    return pt.tanh(super().forward(state))\n",
    "\n",
    "device = pt.device('cuda' if pt.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_rnn(rnn, optimizer, pop, random_policy=False, \n",
    "    num_rollouts=1000, filename='ha_rnn.pt', logger=None):\n",
    "  rnn = rnn.train().to(device)\n",
    "\n",
    "  batch_size = pop.popsize\n",
    "  num_batch = num_rollouts // batch_size\n",
    "\n",
    "  batch_pbar = tqdm(range(num_batch))\n",
    "  for i in batch_pbar:\n",
    "    # sample rollout data\n",
    "    (obs_batch, act_batch), success = pop.rollout(random_policy)\n",
    "    assert success\n",
    "\n",
    "    obs_batch = obs_batch.to(device)\n",
    "    act_batch = act_batch.to(device)\n",
    "\n",
    "    obs_batch, next_obs_batch = obs_batch[:-1], obs_batch[1:]\n",
    "    hid = (pt.zeros(batch_size, rnn.hid_dim).to(device),\n",
    "           pt.zeros(batch_size, rnn.hid_dim).to(device))\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    # compute NLL loss\n",
    "    loss = 0.0\n",
    "    for obs, act, next_obs in zip(obs_batch, act_batch, next_obs_batch):\n",
    "      mu, sigma, hid = rnn(obs, act, hid)\n",
    "      dist = distributions.Normal(loc=mu, scale=sigma)\n",
    "      nll = -dist.log_prob(next_obs) # negative log-likelihood\n",
    "      nll = pt.mean(nll, dim=-1)     # mean over dimensions\n",
    "      nll = pt.mean(nll, dim=0)      # mean over batch\n",
    "      loss += nll\n",
    "    loss = loss / len(act_batch)     # mean over trajectory\n",
    "    val = loss.item()\n",
    "    batch_pbar.set_description('loss= ' + str(val))\n",
    "\n",
    "    # update RNN\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if logger is not None:\n",
    "      logger.push(loss.item())\n",
    "\n",
    "  pt.save(rnn.state_dict(), filename)\n",
    "\n",
    "def evolve_ctrl(ctrl, es, pop, num_gen=100, filename='ha_ctrl.pt', logger=None):\n",
    "  best_sol = None\n",
    "  best_fit = -np.inf\n",
    "\n",
    "  gen_pbar = tqdm(range(num_gen))\n",
    "  for g in gen_pbar:\n",
    "    # upload individuals\n",
    "    inds = es.ask()\n",
    "    success = pop.upload_ctrl(inds)\n",
    "    assert success\n",
    "\n",
    "    # evaluate\n",
    "    fits, success = pop.evaluate()\n",
    "    assert success\n",
    "    \n",
    "    # update\n",
    "    es.tell(fits)\n",
    "    best_sol, best_fit = es.best\n",
    "    gen_pbar.set_description('best=' + str(best_fit))\n",
    "\n",
    "    if logger is not None:\n",
    "      logger.push(best_fit)\n",
    "\n",
    "  ctrl.load_genotype(best_sol)\n",
    "  pt.save(ctrl.state_dict(), filename)\n",
    "\n",
    "def random_rollout(env, seq_len=1600):\n",
    "  obs_dim = env.observation_space.shape[0]\n",
    "  act_dim = env.action_space.n\n",
    "\n",
    "  obs_data = np.zeros((seq_len+1, obs_dim), dtype=np.float32)\n",
    "  act_data = np.zeros((seq_len, act_dim), dtype=np.float32)\n",
    "  \n",
    "  obs = env.reset()\n",
    "  obs_data[0] = obs\n",
    "  for t in range(seq_len):\n",
    "    act = env.action_space.sample()\n",
    "    obs, rew, done, _ = env.step(act)\n",
    "    obs_data[t+1] = obs\n",
    "    act_data[t] = act\n",
    "    if done:\n",
    "      env.close()  \n",
    "      obs = env.reset()\n",
    "\n",
    "  return obs_data, act_data\n",
    "\n",
    "def rollout(env, rnn, ctrl, seq_len=1600, render=False):\n",
    "  obs_dim = env.observation_space.shape[0]\n",
    "  act_dim = env.action_space.shape[0]\n",
    "\n",
    "  obs_data = np.zeros((seq_len+1, obs_dim), dtype=np.float32)\n",
    "  act_data = np.zeros((seq_len, act_dim), dtype=np.float32)\n",
    "  \n",
    "  obs = env.reset()\n",
    "  hid = (pt.zeros(1, rnn.hid_dim), # h\n",
    "         pt.zeros(1, rnn.hid_dim)) # c\n",
    "\n",
    "  obs_data[0] = obs\n",
    "  for t in range(seq_len):\n",
    "    if render:\n",
    "      env.render()\n",
    "    obs = pt.from_numpy(obs).unsqueeze(0)\n",
    "    with pt.no_grad():\n",
    "      act = ctrl(obs, hid[0])\n",
    "      _, _, hid = rnn(obs, act, hid)\n",
    "\n",
    "    act = act.squeeze().numpy()\n",
    "    obs, rew, done, _ = env.step(act)\n",
    "    obs_data[t+1] = obs\n",
    "    act_data[t] = act\n",
    "    if done:\n",
    "      env.close()\n",
    "      obs = env.reset()\n",
    "\n",
    "  return obs_data, act_data\n",
    "\n",
    "def evaluate(env, rnn, ctrl, num_episodes=5, max_episode_steps=1600):\n",
    "  fitness = 0.0\n",
    " \n",
    "  for ep in range(num_episodes):\n",
    "    # Initialize observation and hidden states.\n",
    "    obs = env.reset()\n",
    "    hid = (pt.zeros(1, rnn.hid_dim), # h\n",
    "           pt.zeros(1, rnn.hid_dim)) # c\n",
    "\n",
    "    for t in range(max_episode_steps):\n",
    "      obs = pt.from_numpy(obs).unsqueeze(0)\n",
    "      with pt.no_grad():\n",
    "        # Take an action with the controller.\n",
    "        act = ctrl(obs, hid[0])\n",
    "\n",
    "        # Predict the next observation with the RNN.\n",
    "        _, _, hid = rnn(obs, act, hid)\n",
    "\n",
    "      # Take a step in the environment.\n",
    "      act = act.squeeze().numpy()\n",
    "      obs, rew, done, _ = env.step(act)\n",
    "\n",
    "      fitness += rew\n",
    "      if done:\n",
    "        break\n",
    "\n",
    "  return fitness / num_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population:\n",
    "  def __init__(self, num_workers, agents_per_worker):\n",
    "    self.num_workers = num_workers\n",
    "    self.agents_per_worker = agents_per_worker\n",
    "    self.popsize = num_workers * agents_per_worker\n",
    "\n",
    "    self.pipes = []\n",
    "    self.procs = []\n",
    "    for rank in range(num_workers):\n",
    "      parent_pipe, child_pipe = mp.Pipe()\n",
    "      proc = mp.Process(target=self.worker,\n",
    "                        name='Worker-' + str(rank), \n",
    "                        args=(rank, child_pipe, parent_pipe))\n",
    "      self.pipes.append(parent_pipe)\n",
    "      self.procs.append(proc)\n",
    "      proc.daemon = True\n",
    "      proc.start()\n",
    "      child_pipe.close()\n",
    "\n",
    "  def worker(self, rank, pipe, parent_pipe):\n",
    "    parent_pipe.close()\n",
    "\n",
    "    rng = np.random.RandomState(rank)\n",
    "\n",
    "    #env = BipedalWalker()\n",
    "    #env = gym.make(ENV_NAME).unwrapped\n",
    "    env = gym.make(ENV_NAME)\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.n\n",
    "\n",
    "    rnn = WorldModel(obs_dim, act_dim)\n",
    "    ctrls = [Controller(obs_dim+rnn.hid_dim, act_dim)\n",
    "             for _ in range(self.agents_per_worker)]\n",
    "  \n",
    "    while True:\n",
    "      command, data = pipe.recv()\n",
    "\n",
    "      if command == 'upload_rnn': # data: rnn\n",
    "        rnn.load_state_dict(data.state_dict())\n",
    "        pipe.send((None, True))\n",
    "\n",
    "      elif command == 'upload_ctrl': # data: ([inds], noisy)\n",
    "        inds, noisy = data\n",
    "        for ctrl, ind in zip(ctrls, inds):\n",
    "          if noisy:\n",
    "            ind += rng.normal(scale=1e-3, size=ind.shape)\n",
    "          ctrl.load_genotype(ind)\n",
    "        pipe.send((None, True))\n",
    "\n",
    "      elif command == 'rollout': # data: random_policy\n",
    "        rollouts = []\n",
    "        for ctrl in ctrls:\n",
    "          env.seed(rng.randint(2**31-1))\n",
    "          if data: # if rollout with random policy\n",
    "            trajectory = random_rollout(env)\n",
    "          else:\n",
    "            trajectory = rollout(env, rnn, ctrl)\n",
    "          rollouts.append(trajectory)\n",
    "        pipe.send((rollouts, True))\n",
    "\n",
    "      elif command == 'evaluate': # data: None\n",
    "        evaluations = []\n",
    "        for ctrl in ctrls:\n",
    "          env.seed(rng.randint(2**31-1))\n",
    "          evaluations.append(evaluate(env, rnn, ctrl))\n",
    "        pipe.send((evaluations, True))\n",
    "\n",
    "      elif command == 'close': # data: None\n",
    "        env.close()\n",
    "        pipe.send((None, True))\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "  def upload_rnn(self, rnn):\n",
    "    for p in self.pipes:\n",
    "      p.send(('upload_rnn', rnn))\n",
    "    _, success = zip(*[p.recv() for p in self.pipes])\n",
    "    return all(success)\n",
    "\n",
    "  def upload_ctrl(self, ctrl, noisy=False):\n",
    "    if isinstance(ctrl, np.ndarray):\n",
    "      for p in self.pipes:\n",
    "        inds = [np.copy(ctrl) for _ in range(self.agents_per_worker)]\n",
    "        p.send(('upload_ctrl', (inds, noisy)))\n",
    "    elif isinstance(ctrl, list):\n",
    "      start = 0\n",
    "      for p in self.pipes:\n",
    "        end = start + self.agents_per_worker\n",
    "        inds = [np.copy(c) for c in ctrl[start:end]]\n",
    "        p.send(('upload_ctrl', (inds, noisy)))\n",
    "        start = end\n",
    "    else:\n",
    "      return False\n",
    "\n",
    "    _, success = zip(*[p.recv() for p in self.pipes])\n",
    "    return all(success)\n",
    "\n",
    "  def rollout(self, random_policy):\n",
    "    for p in self.pipes:\n",
    "      p.send(('rollout', random_policy))\n",
    "\n",
    "    rollouts = []\n",
    "    all_success = True\n",
    "    for rollout, success in [p.recv() for p in self.pipes]:\n",
    "      rollouts.extend(rollout)\n",
    "      all_success = all_success and success \n",
    "\n",
    "    obs_batch = []\n",
    "    act_batch = []\n",
    "    for obs, act in rollouts:\n",
    "      obs_batch.append(obs)\n",
    "      act_batch.append(act)\n",
    "\n",
    "    # (seq_len, batch_size, dim)\n",
    "    obs_batch = pt.from_numpy(np.stack(obs_batch, axis=1))\n",
    "    act_batch = pt.from_numpy(np.stack(act_batch, axis=1))\n",
    "    return (obs_batch, act_batch), all_success\n",
    "\n",
    "  def evaluate(self):\n",
    "    for p in self.pipes:\n",
    "      p.send(('evaluate', None))\n",
    "\n",
    "    fits = []\n",
    "    all_success = True\n",
    "    for fit, success in [p.recv() for p in self.pipes]:\n",
    "      fits.extend(fit)\n",
    "      all_success = all_success and success\n",
    "\n",
    "    return fits, all_success\n",
    "\n",
    "  def close(self):\n",
    "    for p in self.pipes:\n",
    "      p.send(('close', None))\n",
    "    _, success = zip(*[p.recv() for p in self.pipes])\n",
    "    return all(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueLogger:\n",
    "  def __init__(self, name, bufsize=100):\n",
    "    self.name = name\n",
    "    self.bufsize = bufsize\n",
    "    self._buffer = np.zeros((bufsize, 2))\n",
    "    self._i = 0 # local iterator\n",
    "    self._t = 0 # global iterator\n",
    "    with open(name + '.csv', 'w') as f:\n",
    "      f.write('step,value\\n')\n",
    "\n",
    "  def push(self, v):\n",
    "    self._buffer[self._i] = (self._t, v)\n",
    "    self._i += 1\n",
    "    self._t += 1\n",
    "    if self._i == self.bufsize:\n",
    "      with open(self.name + '.csv', 'a') as f:\n",
    "        for step, value in self._buffer:\n",
    "          f.write(str(step) + ',' + str(value) + '\\n')\n",
    "      self._buffer.fill(0)\n",
    "      self._i = 0\n",
    "\n",
    "  def plot(self, title, xlabel, ylabel):\n",
    "    dat = pd.read_csv(self.name + '.csv')\n",
    "    steps = dat['step']\n",
    "    values = dat['value']\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.plot(steps, values)\n",
    "    plt.savefig(self.name + '.png')\n",
    "    plt.close(fig=fig)\n",
    "#     running_avg = np.zeros(len(scores))\n",
    "#     for i in range(len(running_avg)):\n",
    "#         running_avg[i] = np.mean(scores[max(0, i-50):(i+1)])\n",
    "#     plt.plot( running_avg)\n",
    "#     plt.title('Running average of previous 50 scores')\n",
    "#     # plt.savefig(figure_file)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT'S DANGEROUS TO GO ALONE! TAKE THIS.\n",
      "<TimeLimit<LunarLanderContinuous<LunarLanderContinuous-v2>>>\n",
      "Initializing agent (device=cuda)...\n",
      "Initializing population with50 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]Process Worker-0:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alik604/anaconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alik604/anaconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-20-cb4bd2e812f5>\", line 29, in worker\n",
      "    act_dim = env.action_space.n\n",
      "AttributeError: 'Box' object has no attribute 'n'\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training M model with a random policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 104] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-09d563e7d8d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m#   args = parser.parse_args()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_get\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rollouts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRANDOMSEED\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENV_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LunarLanderContinuous-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-09d563e7d8d7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training M model with a random policy...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m   train_rnn(rnn, optimizer, pop, random_policy=True, \n\u001b[0m\u001b[1;32m     63\u001b[0m     num_rollouts=args['num_rollouts'], logger=loss_logger)\n\u001b[1;32m     64\u001b[0m   \u001b[0mloss_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'M model training loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-8e1fb0021c0c>\u001b[0m in \u001b[0;36mtrain_rnn\u001b[0;34m(rnn, optimizer, pop, random_policy, num_rollouts, filename, logger)\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_pbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# sample rollout data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mobs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-cb4bd2e812f5>\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, random_policy)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mrollouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mall_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m       \u001b[0mrollouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mall_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_success\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-cb4bd2e812f5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mrollouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mall_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m       \u001b[0mrollouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mall_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_success\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "'''    \n",
    "class NormalizedActions(gym.ActionWrapper):\n",
    "\n",
    "    def _action(self, action):\n",
    "        low  = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "\n",
    "        action = low + (action + 1.0) * 0.5 * (high - low)\n",
    "        action = np.clip(action, low, high)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def _reverse_action(self, action):\n",
    "        low  = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "\n",
    "        action = 2 * (action - low) / (high - low) - 1\n",
    "        action = np.clip(action, low, high)\n",
    "\n",
    "        return action\n",
    "'''\n",
    "\n",
    "def main(args):\n",
    "  print(\"IT'S DANGEROUS TO GO ALONE! TAKE THIS.\")\n",
    "  np.random.seed(args['RANDOMSEED'])\n",
    "  pt.manual_seed(args['RANDOMSEED'])\n",
    "\n",
    "  env = gym.make(args['ENV_NAME'])\n",
    "  print(env)\n",
    "  env.seed(0)\n",
    "  #np.random.seed(RANDOMSEED)\n",
    "  #pt.manual_seed(RANDOMSEED)\n",
    "\n",
    " \n",
    "  #env = NormalizedActions(gym.make(ENV_NAME).unwrapped)\n",
    "\n",
    "  obs_dim = env.observation_space.shape[0]\n",
    "  act_dim = env.action_space.shape[0]\n",
    "#   act_dim = env.action_space.n\n",
    "\n",
    "  print(\"Initializing agent (device=\" +  str(device)  + \")...\")\n",
    "  rnn = WorldModel(obs_dim, act_dim)\n",
    "  ctrl = Controller(obs_dim+rnn.hid_dim, act_dim)\n",
    "\n",
    "  # Adjust population size based on the number of available CPUs.\n",
    "  num_workers = mp.cpu_count() if args['nproc'] is None else args['nproc']\n",
    "  num_workers = min(num_workers, mp.cpu_count())\n",
    "  num_workers = 1\n",
    "  agents_per_worker = args['popsize'] // num_workers\n",
    "  popsize = num_workers * agents_per_worker\n",
    "\n",
    "  print(\"Initializing population with\" + str(popsize) + \" workers...\")\n",
    "  pop = Population(num_workers, agents_per_worker)\n",
    "  global_mu = np.zeros_like(ctrl.genotype)\n",
    "\n",
    "  loss_logger = ValueLogger('ha_rnn_loss', bufsize=20)\n",
    "  best_logger = ValueLogger('ha_ctrl_best', bufsize=100)\n",
    "\n",
    "  # Train the RNN with random policies.\n",
    "  print(\"Training M model with a random policy...\")\n",
    "  optimizer = optim.Adam(rnn.parameters(), lr=args['lr'])\n",
    "  train_rnn(rnn, optimizer, pop, random_policy=True, \n",
    "    num_rollouts=args['num_rollouts'], logger=loss_logger)\n",
    "  loss_logger.plot('M model training loss', 'step', 'loss')\n",
    "  \n",
    "  # Upload the trained RNN.\n",
    "  success = pop.upload_rnn(rnn.cpu())\n",
    "  assert success\n",
    "\n",
    "  # Iteratively update controller and RNN.\n",
    "  for i in range(args['niter']):\n",
    "    # Evolve controllers with the trained RNN.\n",
    "    print(\"Iter.\" + str(i) + \": Evolving C model...\")\n",
    "    es = EvolutionStrategy(global_mu, args['sigma0'], popsize)\n",
    "    evolve_ctrl(ctrl, es, pop, num_gen=args['num_gen'], logger=best_logger)\n",
    "    best_logger.plot('C model evolution', 'gen', 'fitness')\n",
    "\n",
    "    # Update the global best individual and upload them.\n",
    "    global_mu = np.copy(ctrl.genotype)\n",
    "    success = pop.upload_ctrl(global_mu, noisy=True)\n",
    "    assert success\n",
    "    \n",
    "    # Train the RNN with the current best controller.\n",
    "    print(\"Iter.\" + str(i) + \": Training M model...\")\n",
    "    train_rnn(rnn, optimizer, pop, random_policy=False,\n",
    "      num_rollouts=args['num_rollouts'], logger=loss_logger)\n",
    "    loss_logger.plot('M model training loss', 'step', 'loss')\n",
    "\n",
    "    # Upload the trained RNN.\n",
    "    success = pop.upload_rnn(rnn.cpu())\n",
    "    assert success\n",
    "\n",
    "    # Test run!\n",
    "    rollout(env, rnn, ctrl, render=True)\n",
    "\n",
    "  success = pop.close()\n",
    "  assert success\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ###############################  hyper parameters  #########################\n",
    "  # ENV_NAME = 'gazeboros-v0' # 'gazeborosAC-v0'  # environment name\n",
    "  # ENV_NAME = 'LunarLanderContinuous-v2' #'LunarLander-v2'\n",
    "\n",
    "  RANDOMSEED = 42  # random seed\n",
    "#   import argparse\n",
    "#   parser = argparse.ArgumentParser()\n",
    "#   parser.add_argument('--niter', type=int, default=10)\n",
    "#   parser.add_argument('--nproc', type=int, default=1)\n",
    "#   parser.add_argument('--lr', type=float, default=1e-3)\n",
    "#   parser.add_argument('--popsize', type=int, default=50)\n",
    "#   parser.add_argument('--sigma0', type=float, default=0.1)\n",
    "#   parser.add_argument('--num-gen', type=int, default=100)\n",
    "#   parser.add_argument('--num-rollouts', type=int, default=1000)\n",
    "#   parser.add_argument('--RANDOMSEED', type=int, default=42)\n",
    "#   parser.add_argument('--ENV-NAME', type=int, default='LunarLanderContinuous-v2')\n",
    "#   args = parser.parse_args()\n",
    "  args = dict(niter=10, nproc=1, lr=1e-3, popsize=50, sigma0=0.1, num_get=100, num_rollouts=1000, RANDOMSEED=42, ENV_NAME = 'LunarLanderContinuous-v2')\n",
    "  main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('LunarLanderContinuous-v2')\n",
    "# agent = Agent(alpha=0.001, beta=0.001,\n",
    "#         input_dims=env.observation_space.shape, tau=0.005,\n",
    "#         env=env, batch_size=100, layer1_size=400, layer2_size=300,\n",
    "#         n_actions=env.action_space.shape[0])\n",
    "\n",
    "\n",
    "# best_score = 0 # env.reward_range[0]\n",
    "# score_history = []\n",
    "\n",
    "# agent.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(6):\n",
    "#     obs = env.reset()\n",
    "#     done = False\n",
    "#     score = 0\n",
    "#     while not done:\n",
    "#         act = agent.choose_action(obs)\n",
    "#         new_state, reward, done, info = env.step(act)\n",
    "#         agent.remember(obs, act, reward, new_state, int(done))\n",
    "#         agent.learn()\n",
    "#         score += reward\n",
    "#         obs = new_state\n",
    "#         env.render()\n",
    "#     env.close()\n",
    "\n",
    "#     score_history.append(score)\n",
    "#     avg_score = np.mean(score_history[-50:])\n",
    "\n",
    "#     if avg_score > best_score:\n",
    "#         best_score = avg_score\n",
    "#         agent.save_models()\n",
    "\n",
    "#     print('episode ', i, 'score %.2f' % score, 'trailing 50 games avg %.3f' % avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
